{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8598ac87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c03a12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {torch.cuda.get_device_name(device)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8978b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MNIST dataset\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4, pin_memory=True)\n",
    "print(f\"Total training images: {len(train_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d222cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=True, num_workers = 8, pin_memory=True)\n",
    "print(f\"Total test images: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f858ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training a digit classifier before we train the diffusion model \n",
    "class DigitClassifier(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(28 * 28, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f554df34",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = DigitClassifier().to(device)\n",
    "classifier_optimizer = torch.optim.Adam(classifier.parameters(), lr=1e-4)\n",
    "classifier_loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0175815",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = GradScaler()\n",
    "epochs = 100  # Enough for MNIST classification, ~10-15 minutes\n",
    "checkpoint_path_classifier = \"checkpoint_classifier.pth\"\n",
    "\n",
    "if os.path.exists(checkpoint_path_classifier):\n",
    "    try:\n",
    "        checkpoint = torch.load(checkpoint_path_classifier)\n",
    "        classifier.load_state_dict(checkpoint['classifier_state_dict'])\n",
    "        classifier_optimizer.load_state_dict(checkpoint['classifier_optimizer_state_dict'])\n",
    "        start_epoch = checkpoint['epoch'] + 1\n",
    "        losses_per_epoch = checkpoint['losses_per_epoch']\n",
    "        accuracies_per_epoch = checkpoint['accuracies_per_epoch']\n",
    "        print(f\"Resumed classifier training from epoch {start_epoch}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading checkpoint: {e}. Starting fresh.\")\n",
    "        start_epoch = 0\n",
    "        losses_per_epoch = []\n",
    "        accuracies_per_epoch = []\n",
    "else:\n",
    "    start_epoch = 0\n",
    "    losses_per_epoch = []\n",
    "    accuracies_per_epoch = []\n",
    "\n",
    "print(\"Starting classifier training...\")\n",
    "for epoch in range(start_epoch, epochs):\n",
    "    classifier.train()\n",
    "    pbar = tqdm.tqdm(train_dataloader)\n",
    "    total_loss, correct_preds, total_preds = 0, 0, 0\n",
    "\n",
    "    for step, (x, labels) in enumerate(pbar):\n",
    "        try:\n",
    "            x = x.to(device)  # (batch, 1, 28, 28)\n",
    "            labels = labels.to(device)  # (batch), indices 0-9\n",
    "            batch_size = x.shape[0]\n",
    "\n",
    "            with autocast():\n",
    "                flat_x = x.view(batch_size, -1)  # Flatten to (batch, 784)\n",
    "                pred_labels = classifier(flat_x)  # Should be (batch, 10)\n",
    "                loss = classifier_loss(pred_labels, labels)  # Ensure labels are indices\n",
    "\n",
    "            classifier_optimizer.zero_grad()\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(classifier_optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            _, predicted = torch.max(pred_labels, 1)  # Get predicted class indices\n",
    "            correct_preds += (predicted == labels).sum().item()\n",
    "            total_preds += batch_size\n",
    "            total_loss += loss.item()\n",
    "            accuracy = correct_preds / total_preds * 100\n",
    "            pbar.set_description(f\"Classifier Loss: {loss.item():.4f} | Acc: {accuracy:.2f}%\")\n",
    "        except RuntimeError as e:\n",
    "            print(f\"Runtime error at step {step}: {e}. Skipping batch. Check dimensions or reduce batch size to 32.\")\n",
    "            break\n",
    "        except ValueError as e:\n",
    "            print(f\"Value error at step {step}: {e}. Likely dimension mismatch. pred_labels shape: {pred_labels.shape}, labels shape: {labels.shape}\")\n",
    "            break\n",
    "\n",
    "    if total_preds > 0:\n",
    "        avg_loss = total_loss / (step + 1)  # Adjust for possible early break\n",
    "        accuracy = correct_preds / total_preds * 100\n",
    "        losses_per_epoch.append(avg_loss)\n",
    "        accuracies_per_epoch.append(accuracy)\n",
    "        print(f\"Epoch {epoch+1}/{epochs} | Average Loss: {avg_loss:.6f} | Accuracy: {accuracy:.2f}%\")\n",
    "    else:\n",
    "        print(f\"Epoch {epoch+1}/{epochs} | No valid batches processed. Check data loading.\")\n",
    "        losses_per_epoch.append(float('nan'))\n",
    "        accuracies_per_epoch.append(0.0)\n",
    "\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'classifier_state_dict': classifier.state_dict(),\n",
    "        'classifier_optimizer_state_dict': classifier_optimizer.state_dict(),\n",
    "        'losses_per_epoch': losses_per_epoch,\n",
    "        'accuracies_per_epoch': accuracies_per_epoch,\n",
    "    }, checkpoint_path_classifier)\n",
    "    print(f\"Classifier checkpoint saved at epoch {epoch+1}\")\n",
    "\n",
    "    # Plotting\n",
    "    clear_output(wait=True)\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(range(1, epoch + 2), losses_per_epoch, label='Loss', color='blue')\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Classifier Loss vs Epoch\")\n",
    "    plt.grid(True)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(range(1, epoch + 2), accuracies_per_epoch, label='Accuracy (%)', color='green')\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(\"Classifier Accuracy vs Epoch\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee116441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test DigitClassifier\n",
    "classifier.eval()\n",
    "\n",
    "# Get a batch for testing\n",
    "dataiter = iter(test_dataloader)\n",
    "images, labels = next(dataiter)\n",
    "images, labels = images.to(device), labels.to(device)\n",
    "batch_size = images.shape[0]\n",
    "\n",
    "with torch.no_grad():\n",
    "    flat_images = images.view(batch_size, -1)  # Flatten to (batch, 784)\n",
    "    outputs = classifier(flat_images)  # (batch, 10)\n",
    "    _, predicted = torch.max(outputs, 1)  # Get predicted class indices\n",
    "\n",
    "# Calculate accuracy\n",
    "correct = (predicted == labels).sum().item()\n",
    "accuracy = correct / batch_size * 100\n",
    "print(f\"Test Accuracy on batch: {accuracy:.2f}%\")\n",
    "print(f\"Correct predictions: {correct} out of {batch_size}\")\n",
    "\n",
    "# Visualize some predictions\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 6))\n",
    "axes = axes.ravel()\n",
    "for idx in range(10):\n",
    "    ax = axes[idx]\n",
    "    img = images[idx].cpu().numpy().squeeze()  # (1, 28, 28) -> (28, 28)\n",
    "    ax.imshow(img, cmap='gray')\n",
    "    ax.set_title(f\"True: {labels[idx].item()}\\nPred: {predicted[idx].item()}\")\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d4deac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diffusion schedules\n",
    "T = 1000\n",
    "beta_start, beta_end = 1e-4, 0.02\n",
    "betas = torch.linspace(beta_start, beta_end, T).to(device)\n",
    "alphas = 1. - betas\n",
    "alphas_cumprod = torch.cumprod(alphas, dim=0).to(device)\n",
    "sqrt_alphas_cumprod = torch.sqrt(alphas_cumprod).to(device)\n",
    "sqrt_one_minus_alphas_cumprod = torch.sqrt(1 - alphas_cumprod).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd9b3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward diffusion function\n",
    "def forward_diffusion_sample(x_0, t, device=device):\n",
    "    noise = torch.randn_like(x_0).to(device)\n",
    "    sqrt_alphas_cumprod_t = sqrt_alphas_cumprod[t][:, None, None, None]\n",
    "    sqrt_one_minus_alphas_cumprod_t = sqrt_one_minus_alphas_cumprod[t][:, None, None, None]\n",
    "    x_t = sqrt_alphas_cumprod_t * x_0 + sqrt_one_minus_alphas_cumprod_t * noise\n",
    "    return x_t, noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9020e28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guided UNet model with label conditioning\n",
    "class SinusoidalTimeEmbedding(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "    def forward(self, t):\n",
    "        half_dim = self.dim // 2\n",
    "        emb = math.log(10000) / (half_dim - 1)\n",
    "        emb = torch.exp(torch.arange(half_dim, device=t.device) * -emb)\n",
    "        emb = t[:, None] * emb[None, :]\n",
    "        emb = torch.cat([torch.sin(emb), torch.cos(emb)], dim=1)\n",
    "        if emb.shape[1] < self.dim:\n",
    "            emb = F.pad(emb, (0, self.dim - emb.shape[1]))\n",
    "        return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7161ca39",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, padding=1)\n",
    "        self.shortcut = nn.Conv2d(in_channels, out_channels, 1) if in_channels != out_channels else nn.Identity()\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.conv2(x)\n",
    "        x += self.shortcut(identity)\n",
    "        return F.relu(x)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, time_dim=256, label_dim=10):\n",
    "        super().__init__()\n",
    "        self.time_mlp = nn.Sequential(\n",
    "            SinusoidalTimeEmbedding(time_dim),\n",
    "            nn.Linear(time_dim, time_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(time_dim, time_dim)\n",
    "        )\n",
    "        self.label_mlp = nn.Sequential(\n",
    "            nn.Linear(label_dim, time_dim),  # Map 10-class one-hot to time_dim\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.enc1 = ResidualBlock(1, 64)\n",
    "        self.enc2 = ResidualBlock(64, 128)\n",
    "        self.enc3 = ResidualBlock(128, 256)\n",
    "        self.time_proj1 = nn.Linear(time_dim, 64)\n",
    "        self.time_proj2 = nn.Linear(time_dim, 128)\n",
    "        self.time_proj3 = nn.Linear(time_dim, 256)\n",
    "        self.bottleneck = ResidualBlock(256, 256)\n",
    "        self.dec1 = ResidualBlock(512, 128)  # 256 + 256 from skip\n",
    "        self.dec2 = ResidualBlock(256, 64)   # 128 + 128 from skip\n",
    "        self.dec3 = nn.Conv2d(128, 1, 3, padding=1)  # 64 + 64 from skip\n",
    "\n",
    "    def forward(self, x, t, labels):\n",
    "        t_emb = self.time_mlp(t)\n",
    "        l_emb = self.label_mlp(labels)  # (batch, 10) -> (batch, time_dim)\n",
    "        combined_emb = t_emb + l_emb\n",
    "        x1 = self.enc1(x) + self.time_proj1(combined_emb).unsqueeze(-1).unsqueeze(-1)\n",
    "        x2 = self.enc2(x1) + self.time_proj2(combined_emb).unsqueeze(-1).unsqueeze(-1)\n",
    "        x3 = self.enc3(x2) + self.time_proj3(combined_emb).unsqueeze(-1).unsqueeze(-1)\n",
    "        x = self.bottleneck(x3)\n",
    "        x = self.dec1(torch.cat([x, x3], dim=1))\n",
    "        x = self.dec2(torch.cat([x, x2], dim=1))\n",
    "        x = self.dec3(torch.cat([x, x1], dim=1))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ded8642",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.5e-4)\n",
    "mse_loss = nn.MSELoss()\n",
    "scaler = GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37647359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using FID as a metric\n",
    "from torcheval.metrics.image import FrechetInceptionDistance\n",
    "\n",
    "fid = FrechetInceptionDistance(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30df25a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path_diffusion = 'checkpoint_diffusion.pth'\n",
    "\n",
    "\n",
    "# Load pre-trained classifier\n",
    "checkpoint_classifier = torch.load(\"checkpoint_classifier.pth\")\n",
    "classifier = DigitClassifier().to(device)\n",
    "classifier.load_state_dict(checkpoint_classifier['classifier_state_dict'])\n",
    "classifier.eval()  # Freeze classifier, no training\n",
    "\n",
    "if os.path.exists(checkpoint_path_diffusion):\n",
    "    checkpoint = torch.load(checkpoint_path_diffusion)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    start_epoch = checkpoint['epoch'] + 1\n",
    "    losses_per_epoch = checkpoint['losses_per_epoch']\n",
    "    fids_per_epoch = checkpoint['fids_per_epoch']\n",
    "    print(f\"Resumed diffusion training from epoch {start_epoch}\")\n",
    "else:\n",
    "    start_epoch = 0\n",
    "    losses_per_epoch = []\n",
    "    fids_per_epoch = []\n",
    "    accuracies_per_epoch = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab52c880",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27e7c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4780f53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809293bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting diffusion training...\")\n",
    "for epoch in range(start_epoch, epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
    "    pbar = tqdm.tqdm(train_dataloader)\n",
    "    total_loss = 0\n",
    "    step_count = 0\n",
    "\n",
    "    model.train()\n",
    "    for step, (x, labels) in enumerate(pbar):\n",
    "        x = x.to(device)  # (batch, 1, 28, 28)\n",
    "        labels_one_hot = F.one_hot(labels, num_classes=10).float().to(device)\n",
    "        batch_size = x.shape[0]\n",
    "        t = torch.randint(0, T, (batch_size,), device=device).long()\n",
    "\n",
    "        with autocast():\n",
    "            x_t, noise = forward_diffusion_sample(x, t)\n",
    "            if x_t.shape != noise.shape or x_t.shape[1:] != (1, 28, 28):\n",
    "                raise ValueError(f\"Shape mismatch: x_t {x_t.shape}, noise {noise.shape}\")\n",
    "\n",
    "            noise_pred = model(x_t, t.float(), labels_one_hot)\n",
    "            if noise_pred.shape != noise.shape:\n",
    "                raise ValueError(f\"Shape mismatch: noise_pred {noise_pred.shape}, noise {noise.shape}\")\n",
    "            \n",
    "            loss = mse_loss(noise_pred, noise)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        alpha_bar = sqrt_alphas_cumprod[t][:, None, None, None]\n",
    "        one_minus_alpha_bar = sqrt_one_minus_alphas_cumprod[t][:, None, None, None]\n",
    "        x0_pred = (x_t - one_minus_alpha_bar * noise_pred) / alpha_bar\n",
    "        x0_pred = torch.clamp(x0_pred, -1, 1)\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        step_count += 1\n",
    "        pbar.set_description(f\"Loss: {loss.item():.4f}\")\n",
    "\n",
    "    if step_count > 0:\n",
    "        avg_loss = total_loss / step_count\n",
    "        losses_per_epoch.append(avg_loss)\n",
    "        print(f\"Average Loss: {avg_loss:.6f}\")\n",
    "    else:\n",
    "        print(f\"Epoch {epoch+1}/{epochs} | No valid batches processed. Check data or reduce batch size.\")\n",
    "        losses_per_epoch.append(float('nan'))\n",
    "\n",
    "    # Compute FID every 5 epochs or at the end\n",
    "    if epoch % 5 == 0 or epoch == epochs - 1:\n",
    "        print(\"Computing FID score...\")\n",
    "        model.eval()\n",
    "        fid.reset()\n",
    "        n_samples = 500\n",
    "        batch_size_fid = 64\n",
    "\n",
    "        # Match label distribution from real data\n",
    "        real_labels = []\n",
    "        for _, labels in train_dataloader:\n",
    "            real_labels.extend(labels.numpy())\n",
    "            if len(real_labels) > n_samples:\n",
    "                break\n",
    "        real_labels = np.array(real_labels)[:n_samples]\n",
    "        label_dist = np.bincount(real_labels, minlength=10) / len(real_labels)\n",
    "        labels_all = np.random.choice(10, n_samples, p=label_dist)\n",
    "        labels_all = torch.from_numpy(labels_all).to(device)\n",
    "        labels_one_hot_all = F.one_hot(labels_all, num_classes=10).float()\n",
    "\n",
    "        x_gen_all = []\n",
    "        with torch.no_grad(), autocast():\n",
    "            for i in range(0, n_samples, batch_size_fid):\n",
    "                batch_labels = labels_one_hot_all[i:i + batch_size_fid]\n",
    "                batch_size = min(batch_size_fid, n_samples - i)\n",
    "                x_gen = torch.randn((batch_size, 1, 28, 28)).to(device)\n",
    "                for t in reversed(range(0, T)):\n",
    "                    if t % 100 == 0:\n",
    "                        print(f\"  Denoising step {t} for batch {i//batch_size_fid}/{n_samples//batch_size_fid}\")\n",
    "                    t_batch = torch.full((batch_size,), t, device=device, dtype=torch.long)\n",
    "                    beta_t = betas[t].to(device)\n",
    "                    sqrt_one_minus_alphas_cumprod_t = sqrt_one_minus_alphas_cumprod[t].to(device)\n",
    "                    sqrt_recip_alpha_t = (1.0 / torch.sqrt(alphas[t])).to(device)\n",
    "                    epsilon_theta = model(x_gen, t_batch.float(), batch_labels[:batch_size])\n",
    "                    model_mean = sqrt_recip_alpha_t * (x_gen - beta_t * epsilon_theta / sqrt_one_minus_alphas_cumprod_t)\n",
    "                    if t > 1:\n",
    "                        noise = torch.randn_like(x_gen).to(device)\n",
    "                        sigma_t = torch.sqrt(beta_t)\n",
    "                        x_gen = model_mean + sigma_t * noise\n",
    "                    else:\n",
    "                        x_gen = model_mean\n",
    "                x_gen = torch.clamp(x_gen, -1, 1) * 0.5 + 0.5\n",
    "                x_gen_all.append(x_gen.cpu())\n",
    "\n",
    "        x_gen = torch.cat(x_gen_all, dim=0)[:n_samples]\n",
    "        # Use multiple real batches\n",
    "        real_data_all = []\n",
    "        for _ in range(n_samples // train_dataloader.batch_size + 1):\n",
    "            try:\n",
    "                real_batch, _ = next(iter(train_dataloader))\n",
    "                real_data_all.append(real_batch.to(device))\n",
    "            except StopIteration:\n",
    "                break\n",
    "        real_data = torch.cat(real_data_all, dim=0)[:n_samples]\n",
    "\n",
    "        torch.clamp(x_gen, 0, 1, out=x_gen)\n",
    "        torch.clamp(real_data, 0, 1, out=real_data)\n",
    "\n",
    "        # Try 1-channel FID (if supported by torcheval, otherwise revert to 3-channel)\n",
    "        try:\n",
    "            fid.update(real_data, is_real=True)\n",
    "            fid.update(x_gen, is_real=False)\n",
    "        except ValueError:\n",
    "            # Fallback to 3-channel if 1-channel fails\n",
    "            x_gen_rgb = x_gen.repeat(1, 3, 1, 1)\n",
    "            real_data_rgb = real_data.repeat(1, 3, 1, 1)\n",
    "            fid.update(real_data_rgb, is_real=True)\n",
    "            fid.update(x_gen_rgb, is_real=False)\n",
    "\n",
    "        fid_score = fid.compute().item()\n",
    "        fids_per_epoch.append(fid_score)\n",
    "        print(f\"FID score at epoch {epoch+1}: {fid_score:.2f}\")\n",
    "        # Debug: Save a sample image\n",
    "        sample_img = x_gen[0].cpu().numpy().squeeze()\n",
    "        plt.imsave(f'sample_epoch_{epoch+1}.png', sample_img, cmap='gray')\n",
    "        print(f\"Saved sample image at epoch {epoch+1}\")\n",
    "        model.train()\n",
    "\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'losses_per_epoch': losses_per_epoch,\n",
    "        'fids_per_epoch': fids_per_epoch,\n",
    "    }, checkpoint_path_diffusion)\n",
    "    print(f\"Diffusion checkpoint saved at epoch {epoch+1}\")\n",
    "\n",
    "    # Plotting\n",
    "    clear_output(wait=True)\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    x_range = range(1, len(losses_per_epoch) + 1)\n",
    "    plt.plot(x_range, losses_per_epoch, label='MSE Loss')\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Loss vs Epoch\")\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    x_range_fid = range(1, len(fids_per_epoch) + 1)\n",
    "    plt.plot(x_range_fid, fids_per_epoch, label='FID Score', color='green')\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"FID\")\n",
    "    plt.title(\"FID vs Epoch\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Optional: Add learning rate scheduling\n",
    "    if 'scheduler' in locals():\n",
    "        scheduler.step(avg_loss)\n",
    "        print(f\"Learning rate adjusted to {optimizer.param_groups[0]['lr']:.6f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
