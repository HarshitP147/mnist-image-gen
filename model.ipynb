{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5660cfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74fd52d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: NVIDIA GeForce RTX 3050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "# Set up device and optimizations\n",
    "torch.backends.cudnn.benchmark = True\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05cae89f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training images: 60000\n"
     ]
    }
   ],
   "source": [
    "# Load MNIST dataset\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2, pin_memory=True)\n",
    "print(f\"Total training images: {len(train_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83b8e1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diffusion schedules\n",
    "T = 1000\n",
    "beta_start, beta_end = 1e-4, 0.02\n",
    "betas = torch.linspace(beta_start, beta_end, T).to(device)\n",
    "alphas = 1. - betas\n",
    "alphas_cumprod = torch.cumprod(alphas, dim=0).to(device)\n",
    "sqrt_alphas_cumprod = torch.sqrt(alphas_cumprod).to(device)\n",
    "sqrt_one_minus_alphas_cumprod = torch.sqrt(1 - alphas_cumprod).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67e7ade5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward diffusion function\n",
    "def forward_diffusion_sample(x_0, t, device=device):\n",
    "    noise = torch.randn_like(x_0).to(device)\n",
    "    sqrt_alphas_cumprod_t = sqrt_alphas_cumprod[t][:, None, None, None]\n",
    "    sqrt_one_minus_alphas_cumprod_t = sqrt_one_minus_alphas_cumprod[t][:, None, None, None]\n",
    "    x_t = sqrt_alphas_cumprod_t * x_0 + sqrt_one_minus_alphas_cumprod_t * noise\n",
    "    return x_t, noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dee5a076",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# Guided UNet model with label conditioning\n",
    "class SinusoidalTimeEmbedding(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "    def forward(self, t):\n",
    "        half_dim = self.dim // 2\n",
    "        emb = math.log(10000) / (half_dim - 1)\n",
    "        emb = torch.exp(torch.arange(half_dim, device=t.device) * -emb)\n",
    "        emb = t[:, None] * emb[None, :]\n",
    "        emb = torch.cat([torch.sin(emb), torch.cos(emb)], dim=1)\n",
    "        if emb.shape[1] < self.dim:\n",
    "            emb = F.pad(emb, (0, self.dim - emb.shape[1]))\n",
    "        return emb\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, padding=1)\n",
    "        self.shortcut = nn.Conv2d(in_channels, out_channels, 1) if in_channels != out_channels else nn.Identity()\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.conv2(x)\n",
    "        x += self.shortcut(identity)\n",
    "        return F.relu(x)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, time_dim=256, label_dim=10):\n",
    "        super().__init__()\n",
    "        self.time_mlp = nn.Sequential(\n",
    "            SinusoidalTimeEmbedding(time_dim),\n",
    "            nn.Linear(time_dim, time_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(time_dim, time_dim)\n",
    "        )\n",
    "        self.label_mlp = nn.Sequential(\n",
    "            nn.Linear(label_dim, time_dim),  # Map 10-class one-hot to time_dim\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.enc1 = ResidualBlock(1, 64)\n",
    "        self.enc2 = ResidualBlock(64, 128)\n",
    "        self.enc3 = ResidualBlock(128, 256)\n",
    "        self.time_proj1 = nn.Linear(time_dim, 64)\n",
    "        self.time_proj2 = nn.Linear(time_dim, 128)\n",
    "        self.time_proj3 = nn.Linear(time_dim, 256)\n",
    "        self.bottleneck = ResidualBlock(256, 256)\n",
    "        self.dec1 = ResidualBlock(512, 128)  # 256 + 256 from skip\n",
    "        self.dec2 = ResidualBlock(256, 64)   # 128 + 128 from skip\n",
    "        self.dec3 = nn.Conv2d(128, 1, 3, padding=1)  # 64 + 64 from skip\n",
    "\n",
    "    def forward(self, x, t, labels):\n",
    "        t_emb = self.time_mlp(t)\n",
    "        l_emb = self.label_mlp(labels)  # (batch, 10) -> (batch, time_dim)\n",
    "        combined_emb = t_emb + l_emb\n",
    "        x1 = self.enc1(x) + self.time_proj1(combined_emb).unsqueeze(-1).unsqueeze(-1)\n",
    "        x2 = self.enc2(x1) + self.time_proj2(combined_emb).unsqueeze(-1).unsqueeze(-1)\n",
    "        x3 = self.enc3(x2) + self.time_proj3(combined_emb).unsqueeze(-1).unsqueeze(-1)\n",
    "        x = self.bottleneck(x3)\n",
    "        x = self.dec1(torch.cat([x, x3], dim=1))\n",
    "        x = self.dec2(torch.cat([x, x2], dim=1))\n",
    "        x = self.dec3(torch.cat([x, x1], dim=1))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2c774e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model = UNet().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "mse = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abd16143",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69811/1862165192.py:1: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    }
   ],
   "source": [
    "scaler = GradScaler()\n",
    "epochs = 200\n",
    "checkpoint_path = \"checkpoint_guided.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54b79272",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if os.path.exists(checkpoint_path):\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    start_epoch = checkpoint['epoch'] + 1\n",
    "    losses_per_epoch = checkpoint['losses_per_epoch']\n",
    "    psnrs_per_epoch = checkpoint['psnrs_per_epoch']\n",
    "    accuracies_per_epoch = checkpoint['accuracies_per_epoch']\n",
    "    print(f\"Resumed from epoch {start_epoch}\")\n",
    "else:\n",
    "    start_epoch = 0\n",
    "    losses_per_epoch = []\n",
    "    psnrs_per_epoch = []\n",
    "    accuracies_per_epoch = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32806006",
   "metadata": {},
   "outputs": [],
   "source": [
    "def psnr(pred, target, max_val=1.0):\n",
    "    mse = torch.mean((pred-target) ** 2)\n",
    "    return 20 * torch.log10(max_val / torch.sqrt(mse)) if mse > 0 else float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98ec6e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Digit classifier to evaluate accuracy (using a small MLP)\n",
    "class DigitClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(28 * 28, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3a8a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = DigitClassifier().to(device)\n",
    "classifier_optimizer = torch.optim.Adam(classifier.parameters(), lr=1e-4)\n",
    "classifier_criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1461e596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumed classifier training from epoch 70\n",
      "Starting classifier training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69811/4293556471.py:7: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    }
   ],
   "source": [
    "import math  # Ensure math is available\n",
    "\n",
    "# Train DigitClassifier\n",
    "classifier = DigitClassifier().to(device)\n",
    "classifier_optimizer = torch.optim.Adam(classifier.parameters(), lr=1e-4)\n",
    "classifier_criterion = nn.CrossEntropyLoss()\n",
    "scaler = GradScaler()\n",
    "epochs = 70  # Enough for MNIST classification, ~10-15 minutes\n",
    "checkpoint_path_classifier = \"checkpoint_classifier.pth\"\n",
    "\n",
    "if os.path.exists(checkpoint_path_classifier):\n",
    "    try:\n",
    "        checkpoint = torch.load(checkpoint_path_classifier)\n",
    "        classifier.load_state_dict(checkpoint['classifier_state_dict'])\n",
    "        classifier_optimizer.load_state_dict(checkpoint['classifier_optimizer_state_dict'])\n",
    "        start_epoch = checkpoint['epoch'] + 1\n",
    "        losses_per_epoch = checkpoint['losses_per_epoch']\n",
    "        accuracies_per_epoch = checkpoint['accuracies_per_epoch']\n",
    "        print(f\"Resumed classifier training from epoch {start_epoch}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading checkpoint: {e}. Starting fresh.\")\n",
    "        start_epoch = 0\n",
    "        losses_per_epoch = []\n",
    "        accuracies_per_epoch = []\n",
    "else:\n",
    "    start_epoch = 0\n",
    "    losses_per_epoch = []\n",
    "    accuracies_per_epoch = []\n",
    "\n",
    "print(\"Starting classifier training...\")\n",
    "for epoch in range(start_epoch, epochs):\n",
    "    classifier.train()\n",
    "    pbar = tqdm.tqdm(train_dataloader)\n",
    "    total_loss, correct_preds, total_preds = 0, 0, 0\n",
    "\n",
    "    for step, (x, labels) in enumerate(pbar):\n",
    "        try:\n",
    "            x = x.to(device)  # (batch, 1, 28, 28)\n",
    "            labels = labels.to(device)  # (batch), indices 0-9\n",
    "            batch_size = x.shape[0]\n",
    "\n",
    "            with autocast():\n",
    "                flat_x = x.view(batch_size, -1)  # Flatten to (batch, 784)\n",
    "                pred_labels = classifier(flat_x)  # Should be (batch, 10)\n",
    "                loss = classifier_criterion(pred_labels, labels)  # Ensure labels are indices\n",
    "\n",
    "            classifier_optimizer.zero_grad()\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(classifier_optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "            _, predicted = torch.max(pred_labels, 1)  # Get predicted class indices\n",
    "            correct_preds += (predicted == labels).sum().item()\n",
    "            total_preds += batch_size\n",
    "            total_loss += loss.item()\n",
    "            accuracy = correct_preds / total_preds * 100\n",
    "            pbar.set_description(f\"Classifier Loss: {loss.item():.4f} | Acc: {accuracy:.2f}%\")\n",
    "        except RuntimeError as e:\n",
    "            print(f\"Runtime error at step {step}: {e}. Skipping batch. Check dimensions or reduce batch size to 32.\")\n",
    "            break\n",
    "        except ValueError as e:\n",
    "            print(f\"Value error at step {step}: {e}. Likely dimension mismatch. pred_labels shape: {pred_labels.shape}, labels shape: {labels.shape}\")\n",
    "            break\n",
    "\n",
    "    if total_preds > 0:\n",
    "        avg_loss = total_loss / (step + 1)  # Adjust for possible early break\n",
    "        accuracy = correct_preds / total_preds * 100\n",
    "        losses_per_epoch.append(avg_loss)\n",
    "        accuracies_per_epoch.append(accuracy)\n",
    "        print(f\"Epoch {epoch+1}/{epochs} | Average Loss: {avg_loss:.6f} | Accuracy: {accuracy:.2f}%\")\n",
    "    else:\n",
    "        print(f\"Epoch {epoch+1}/{epochs} | No valid batches processed. Check data loading.\")\n",
    "        losses_per_epoch.append(float('nan'))\n",
    "        accuracies_per_epoch.append(0.0)\n",
    "\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'classifier_state_dict': classifier.state_dict(),\n",
    "        'classifier_optimizer_state_dict': classifier_optimizer.state_dict(),\n",
    "        'losses_per_epoch': losses_per_epoch,\n",
    "        'accuracies_per_epoch': accuracies_per_epoch,\n",
    "    }, checkpoint_path_classifier)\n",
    "    print(f\"Classifier checkpoint saved at epoch {epoch+1}\")\n",
    "\n",
    "    # Plotting\n",
    "    clear_output(wait=True)\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(range(1, epoch + 2), losses_per_epoch, label='Loss', color='blue')\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Classifier Loss vs Epoch\")\n",
    "    plt.grid(True)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(range(1, epoch + 2), accuracies_per_epoch, label='Accuracy (%)', color='green')\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(\"Classifier Accuracy vs Epoch\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "654069dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy on batch: 100.00%\n",
      "Correct predictions: 64 out of 64\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABKUAAAI1CAYAAAAHC0kyAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAAU2xJREFUeJzt/X3c1/P9P/7fDx2dHaVYkghFwvROK2eR806cz2lShpAwrA1tzPlZjBlr5mQaM+UkMzVzbsKw7UNOVpYllUSiREWnx+v3h69+S/U4Oo7XcTxfx+s4rtfLpT963V7P5/P+ynHvdXTzPI6jJJfL5QIAAAAAMrReoQcAAAAAoP5RSgEAAACQOaUUAAAAAJlTSgEAAACQOaUUAAAAAJlTSgEAAACQOaUUAAAAAJlTSgEAAACQOaUUAAAAAJlTSgEAAACQOaVUAZSUlKzTr/Hjxxd61NWMHz8+OfPVV19d6BGh2tlZKB7FvK9z586N66+/Pvbaa69o3bp1bLDBBrHbbrvFAw88UOjRoEYV895GRCxcuDCGDh0a7dq1i8aNG8f2228ft956a6HHghpT7DsbETFu3Ljo1q1bNGnSJLbYYou49NJLY/ny5YUeq14qLfQA9dEf//jHVX5/zz33xNNPP73a49tvv32WY62T7bfffrU5I75+TU899VT06dOnAFNBzbKzUDyKeV9feeWV+PnPfx4HHXRQXHTRRVFaWhp/+tOfon///vH222/H5ZdfXugRoUYU896uWLEi+vbtG6+++mr88Ic/jG222SaefPLJOPPMM+Ozzz6LCy+8sNAjQrUr5p2NiHj88cfj8MMPj3322SdGjBgR//73v+Oqq66KOXPmKJQLoCSXy+UKPUR9d9ZZZ8Utt9wSFf2n+PLLL6OsrCyjqSpnm222iZKSkvjvf/9b6FGgxtlZKB7FtK/Tpk2L9dZbL7bccsuVj+VyuejVq1e89NJLMXfu3GjWrFkBJ4RsFNPejhkzJvr16xcjR46Mk08+eeXjRx99dPz1r3+NGTNmxMYbb1zACaHmFdPORkTssMMO0bBhw3j11VejtPTr+3QuuuiiuOaaa+Ltt9+O7bbbrsAT1i++fK+W2meffaJz587x2muvxV577RVlZWUr/09LSUlJXHbZZasd0759+zjppJNWeWz+/PkxdOjQ2HzzzaNx48bRsWPHuO6666K8vHyV53300UcxefLkWLZsWaVn/de//hXvvvtuDBw4sNLHQl1hZ6F41NZ97dChwyqF1DfzHH744bFkyZJ47733Kv9ioY6orXv74osvRkRE//79V3m8f//+sXjx4hg7dmwlXynUDbV1Z99+++14++2347TTTltZSEVEnHnmmZHL5eKhhx6q2gumynz5Xi02d+7cOPDAA6N///5x/PHHR5s2bSp1/Jdffhl77713zJo1K4YMGRJbbLFFvPzyy3HBBRfERx99FDfddNPK515wwQXxhz/8IaZNmxbt27ev1HVGjRoVEeEfuNR7dhaKR7Hsa0TE7NmzIyJio402qvSxUJfUxr1dsmRJNGjQIBo1arTK49/cDfLaa6/F4MGDKzUn1BW1cWdff/31iIjYaaedVnl80003jXbt2q3MyY5SqhabPXt23HbbbTFkyJAqHX/jjTfG1KlT4/XXX49tttkmIiKGDBkSm266aVx//fVx7rnnxuabb57XjCtWrIgHHnggdtlll+jYsWNe54JiZ2eheBTDvkZEzJs3L+68887Yc889o23btnmfD4pZbdzbbbfdNlasWBH/+Mc/omfPnisf/+YOqlmzZlVpVqgLauPOfvTRRxERa3xPbdu2bXz44YdVmpWq8+V7tVjjxo1j0KBBVT5+zJgxseeee8aGG24Yn3766cpfvXr1ihUrVsQLL7yw8rl333135HK5Sv8f3GeffTY+/vhjd1xA2FkoJsWwr+Xl5TFw4MCYP39+jBgxosqzQl1RG/d2wIAB0bJlyzj55JPj6aefjunTp8cdd9wRv/3tbyMi4quvvqryvFDsauPOfrOTjRs3Xi1r0qSJnS0Ad0rVYpttttlqtwJXxpQpU+Ktt96K1q1brzGfM2dOlc/9jVGjRkWDBg3i2GOPzftcUOzsLBSPYtjXs88+O5544om45557Yscdd8z7fFDsauPebrLJJjFu3Lj4wQ9+sPIn2rZo0SJGjBgRJ554YjRv3rzK80Kxq40727Rp04j4+ktvv23x4sUrc7KjlKrFKrsQK1asWOX35eXl0bt37xg2bNgan9+pU6cqzxbxdcv85z//OXr16lXprw+GusjOQvGo7ft6+eWXx29/+9u49tpr4wc/+EFe54K6orbu7V577RXvvfde/Pvf/45FixbFjjvuuPJLgPL9uwCKWW3c2W++bO+jjz5a7Uv/Pvroo9hll10qfU7yo5QqQhtuuGHMnz9/lceWLl268utjv7H11lvHwoULo1evXjUyx7hx42LBggW+DAgqYGeheNSGfb3lllvisssui6FDh8ZPf/rTaj8/1DW1YW8bNGgQXbt2Xfn7Z555JiKixt7ToZgVcme/2dNXX311lQLqww8/jA8++CBOO+20arsW68b3lCpCW2+99SpfPxsRcccdd6zWLPfr1y9eeeWVePLJJ1c7x/z582P58uUrf1+VHy8/evToKCsriyOOOKKSrwDqFzsLxaPQ+/rAAw/EOeecEwMHDowbb7yxiq8C6pdC7+23ffLJJ3HddddFly5dlFKwBoXc2R122CG222671a536623RklJSRx99NFVeUnkwZ1SRejUU0+N008/PY466qjo3bt3vPnmm/Hkk0+u9qOizz///Bg3blwccsghcdJJJ0X37t1j0aJF8e9//zseeuihmD59+spjKvvjqufNmxePP/54HHXUUb5WHipgZ6F4FHJf//Wvf8UJJ5wQrVq1iv333z9GjRq1Sr777rvHVlttVe2vGYpdod9n99577+jRo0d07NgxZs+eHXfccUcsXLgwHn300VhvPfcAwLcVemevv/76OOyww6JPnz7Rv3//mDhxYvzmN7+JU089NbbffvuaetmshVKqCA0ePDimTZsWI0eOjCeeeCL23HPPePrpp2P//fdf5XllZWXx/PPPxzXXXBNjxoyJe+65J1q0aBGdOnWKyy+/PFq2bFnlGcaMGRPLli2LAQMG5PtyoM6zs1A8Crmvb7/9dixdujQ++eSTOPnkk1fL77rrLqUUrEGh32e7d+8eY8aMiVmzZkWLFi2id+/eceWVV9pXWItC7+whhxwSDz/8cFx++eVx9tlnR+vWrePCCy+MSy65pDpeHpVUksvlcoUeAgAAAID6xf2kAAAAAGROKQUAAABA5pRSAAAAAGROKQUAAABA5pRSAAAAAGROKQUAAABA5pRS9VT79u3jpJNOKvQYwDqys1Bc7CwUFzsLxcXO1h1KqQK4++67o6SkZOWvJk2aRKdOneKss86Kjz/+uNDjVeiyyy5bZf5v/3rppZcKPSJUKzsLxaXYd3by5MkxbNiw6Nq1a6y//vrRtm3bOPjgg+PVV18t9GhQI4p9ZyMi3n333Tj66KNjww03jLKysujZs2c899xzhR4LakRd2Nny8vL4xS9+ER06dIgmTZpEly5d4r777iv0WPVSaaEHqM+uuOKK6NChQyxevDj+/ve/x6233hqPPfZYTJw4McrKygo93lodeeSR0bFjx9Uev/DCC2PhwoWx8847F2AqqHl2FopLse7snXfeGSNHjoyjjjoqzjzzzPj888/j9ttvj9122y2eeOKJ6NWrV6FHhBpRrDs7c+bM6NGjRzRo0CDOP//8aNasWdx1113Rp0+fePbZZ2OvvfYq9IhQI4p1ZyMifv7zn8e1114bgwcPjp133jnGjh0bAwYMiJKSkujfv3+hx6tfcmTurrvuykVE7v/9v/+3yuM/+clPchGRGz169FqPXbhwYbXMsOWWW+ZOPPHEajlXLpfLvf/++7mSkpLc4MGDq+2cUFvYWSguxb6zr776am7BggWrPPbpp5/mWrdundtjjz2qYTqoXYp9Z88888xcaWlpbvLkySsfW7RoUW7zzTfPdevWrVrmg9qk2Hf2gw8+yDVs2DD3wx/+cOVj5eXluT333DPXrl273PLly6tlRtaNL9+rRfbbb7+IiJg2bVpERJx00knRvHnzmDp1ahx00EGx/vrrx8CBAyPi69sNb7rppthhhx2iSZMm0aZNmxgyZEh89tlnq5wzl8vFVVddFe3atYuysrLYd999Y9KkSWu8/tSpU2Pq1KlVmv2+++6LXC63cj6oD+wsFJdi2dnu3btH8+bNV3msVatWseeee8Z//vOfSr9uKFbFsrMvvvhifO9734ttt9125WNlZWVx2GGHxYQJE2LKlClVev1QbIplZ8eOHRvLli2LM888c+VjJSUlccYZZ8QHH3wQr7zySpVeP1Xjy/dqkW8WqFWrVisfW758efTt2zd69uwZN9xww8rbIIcMGRJ33313DBo0KM4555yYNm1a/OY3v4nXX389XnrppWjYsGFERFxyySVx1VVXxUEHHRQHHXRQTJgwIfr06RNLly5d7fr7779/RERMnz690rOPGjUqNt98c7cnU6/YWSguxbyzERGzZ8+OjTbaqErHQjEqlp1dsmRJbLjhhqs9/s1sr732WmyzzTaV/wOAIlMsO/v6669Hs2bNYvvtt1/l8V122WVl3rNnz6r9IVB5BbxLq9765nbHZ555JvfJJ5/kZs6cmbv//vtzrVq1yjVt2jT3wQcf5HK5XO7EE0/MRUTuZz/72SrHv/jii7mIyI0aNWqVx5944olVHp8zZ06uUaNGuYMPPjhXXl6+8nkXXnhhLiJWu91xyy23zG255ZaVfj0TJ07MRURu2LBhlT4WioGdheJS13Y2l8vlXnjhhVxJSUnu4osvrtLxUJsV+84eeuihuQ022CD3xRdfrPJ4jx49chGRu+GGG9b1jwKKQrHv7MEHH5zbaqutVnt80aJFa5yXmuXL9wqoV69e0bp169h8882jf//+0bx58/jzn/8cm2222SrPO+OMM1b5/ZgxY6Jly5bRu3fv+PTTT1f++uZ2/29+0sczzzwTS5cujbPPPjtKSkpWHj906NA1zjN9+vQq33EREb4MiDrPzkJxqSs7O2fOnBgwYEB06NAhhg0bVunjoVgU686eccYZMX/+/Dj22GPj9ddfj//+978xdOjQlT8x86uvvqrEnwIUj2Ld2a+++ioaN2682uNNmjRZmZMdX75XQLfcckt06tQpSktLo02bNrHtttvGeuut2hOWlpZGu3btVnlsypQp8fnnn8fGG2+8xvPOmTMnIiJmzJgREbHa7cKtW7de4y3GVZHL5WL06NHRuXPn6NKlS7WcE2orOwvFpS7s7KJFi+KQQw6JBQsWxN///vfVvtcU1CXFurMHHnhgjBgxIn72s59Ft27dIiKiY8eOcfXVV8ewYcPsLXVWse5s06ZNY8mSJas9vnjx4pU52VFKFdAuu+wSO+20U/I5jRs3Xm2xy8vLY+ONN155t8O3tW7dutpmrMhLL70UM2bMiOHDh2d2TSgUOwvFpdh3dunSpXHkkUfGW2+9FU8++WR07tw5k+tCoRTzzp511lkxaNCgeOutt6JRo0bRtWvXGDlyZEREdOrUqcavD4VQrDvbtm3beO655yKXy61yB9ZHH30UERGbbrppjV6fVSmlitDWW28dzzzzTOyxxx7JFnfLLbeMiK+b6K222mrl45988slqP9WgqkaNGhUlJSUxYMCAajkf1EV2FopLbdjZ8vLyOOGEE+LZZ5+NBx98MPbee++8zgd1WW3Y2YiIZs2aRY8ePVb+/plnnommTZvGHnvskfe5oS4p9M527do17rzzzvjPf/4T3/3ud1c+/s9//nNlTnZ8T6ki1K9fv1ixYkVceeWVq2XLly+P+fPnR8TXX+PbsGHDGDFiRORyuZXPuemmm9Z43sr+ePlly5bFmDFjomfPnrHFFltU6jVAfWJnobjUhp09++yz44EHHojf/va3ceSRR1b6NUB9Uht29ttefvnlePjhh+OUU06Jli1bVukcUFcVeme///3vR8OGDeO3v/3tysdyuVzcdtttsdlmm8Xuu+9euRdEXtwpVYT23nvvGDJkSAwfPjzeeOON6NOnTzRs2DCmTJkSY8aMiZtvvjmOPvroaN26dZx33nkxfPjwOOSQQ+Kggw6K119/PR5//PE1/kjpyv6o6ieffDLmzp3rmyVDBewsFJdC7+xNN90Uv/3tb6NHjx5RVlYW99577yr5EUccEc2aNau21wvFrtA7O2PGjOjXr18cdthhsckmm8SkSZPitttuiy5dusQ111xTEy8Zilqhd7Zdu3YxdOjQuP7662PZsmWx8847xyOPPBIvvvhijBo1Kho0aFATL5u1UEoVqdtuuy26d+8et99+e1x44YVRWloa7du3j+OPP36VW4SvuuqqaNKkSdx2223x3HPPxa677hpPPfVUHHzwwXnPMGrUqGjYsGEcc8wxeZ8L6jo7C8WlkDv7xhtvRETEK6+8Eq+88spq+bRp05RS8C2F3NkWLVpE27Zt4ze/+U3MmzcvNttsszjnnHPi5z//eay//vrV8fKgzin058bXXnttbLjhhnH77bfH3XffHdtss03ce++9vsVFAZTk/vc+OAAAAADIgO8pBQAAAEDmlFIAAAAAZE4pBQAAAEDmlFIAAAAAZE4pBQAAAEDmlFIAAAAAZE4pBQAAAEDmStf1iSUlJTU5B7AGuVyuysfaWcienYXiYmehuNhZKC7rsrPulAIAAAAgc0opAAAAADKnlAIAAAAgc0opAAAAADKnlAIAAAAgc0opAAAAADKnlAIAAAAgc0opAAAAADKnlAIAAAAgc0opAAAAADKnlAIAAAAgc0opAAAAADKnlAIAAAAgc0opAAAAADKnlAIAAAAgc0opAAAAADKnlAIAAAAgc0opAAAAADKnlAIAAAAgc0opAAAAADKnlAIAAAAgc0opAAAAADKnlAIAAAAgc0opAAAAADKnlAIAAAAgc0opAAAAADKnlAIAAAAgc0opAAAAADKnlAIAAAAgc0opAAAAADKnlAIAAAAgc6WFHgAAoJgdf/zxyfy8885L5l26dMnr+vfcc08yP+GEE6p87pKSkmT+t7/9LZkfc8wxyXzevHmVngkAqDvcKQUAAABA5pRSAAAAAGROKQUAAABA5pRSAAAAAGROKQUAAABA5pRSAAAAAGROKQUAAABA5kpyuVxunZ5YUlLTswDfso7ruUZ2FrJnZ2unDTbYIJn/6le/Subbb799Mu/atWsyb9iwYTKvyx588MFkftxxx2U0yZrZWSgudhaKy7rsrDulAAAAAMicUgoAAACAzCmlAAAAAMicUgoAAACAzCmlAAAAAMicUgoAAACAzCmlAAAAAMhcaaEHAFiT73znO2vNWrRokTx2+vTpyXzrrbdO5n369Enm22+/fTI/9dRTk3nTpk2TeUVyuVwyLykpSeb33XdfMr/88suT+TvvvJPMobbp3bt3Mj/hhBMymqT+2XvvvZP57rvvnsxffvnl6hyHWmLQoEHJfMiQIcl8k002SeYffvhhMr/llluS+ahRo5I5kK3hw4cn87322iuZ33XXXcl88uTJyfzvf/97Mic/7pQCAAAAIHNKKQAAAAAyp5QCAAAAIHNKKQAAAAAyp5QCAAAAIHNKKQAAAAAyV5Kr6GeLf/PECn7EeL4OPPDAZN6jR4+8zv/9739/rdn//d//JY+t6LWv4x/hWt1zzz3J/P3338/r/Pl6/fXXk/mcOXOSebNmzZL5iy++mMy/+uqrZF6X5fOxVdM7m682bdok87/85S9rzbbbbrvksRX9CPGKfmxs48aNk3ldt2TJkmQ+ePDgZF6ff5R2Xd7ZYrbLLrsk8z/96U/JfNNNN63OcardCy+8kMzvvPPOZP7QQw9V+dgBAwYk84qcdtppyXzkyJF5nb8idrZmnHHGGcl8xIgRyfyjjz5K5hMnTkzmFX2OUdHn/hW9z919993JnJpjZ2unRo0aJfM99tgjmV9wwQXJfL/99kvmDRo0SObl5eXJfPny5cn8r3/9azI/8sgjk3l9ti47604pAAAAADKnlAIAAAAgc0opAAAAADKnlAIAAAAgc0opAAAAADKnlAIAAAAgc0opAAAAADJXksvlcuv0xJKSvC60/vrrJ/Nnn302mXfv3j2v61N7/eIXv0jmF1xwQUaT1D7ruJ5rlO/O1rQxY8Yk8yOPPDKjSSpv+fLlyXzx4sXJ/I477qjOcVZzwAEHJPPtt98+mVf0sVPR60v9ff6Xv/wleezIkSOTeXl5eTIvtLq8s3XZk08+mcx79eqVzKdOnZrM582bl8zPO++8ZF6RyZMnJ/NPP/00mZeVla01Gz16dPLYQw89NJm//fbbybx3797JfPbs2ck8X3a2ao455phkPmrUqGT+wQcfJPOKPi4q2rlGjRol8ylTpiTzadOmJfN99tknmVNz7Gzt1LFjx2T+zjvv1Oj1K/pvm8/HTUTEkiVLkvn111+fzC+99NK8rl/M1uXP3p1SAAAAAGROKQUAAABA5pRSAAAAAGROKQUAAABA5pRSAAAAAGROKQUAAABA5pRSAAAAAGSuNKsLnXvuucm8e/fuyby8vDyZz58/v7IjZaa0NP3H3KJFi4wmqZ0WL15c6BGoAW3atEnmu+66a41de8GCBcl86tSpyfz2229P5uPGjUvms2fPTuY17fzzz0/mRx11VDL/9a9/ncw32WSTZH7wwQdXKYuI6NatWzIfOnRoMl+yZEkyhzX53e9+l8yfeuqpZH7rrbcm8y+//LLSM2Xp2muvXWt26KGH5nXuhQsXJvNC/31J1ey2227JvKLPfSdNmpTMK3qfrsjSpUuTed++fZP5yy+/nNfxzz//fDL3uS/F5uyzz07m5513Xl7nHzlyZDKv6HP7H//4x3ldvyKNGzfO6/p9+vRZa/bVV18lj91vv/2SeV3gTikAAAAAMqeUAgAAACBzSikAAAAAMqeUAgAAACBzSikAAAAAMqeUAgAAACBzSikAAAAAMleSy+Vy6/TEkpK8LtSoUaNk/sMf/jCZ/+AHP0jm3bp1q/RMWdl0002T+fe///2MJqmaK6+8MplvuOGGeZ2/ZcuWyXzhwoV5nb+YreN6rlG+O5uvij7uX3vttWTeunXrtWYjR45MHjtixIhkPnHixGRe3w0fPjyZDxs2LKNJVrftttsm83fffTejSdasmHeWuuucc85J5r/85S/Xmq23Xn7//7JHjx7J/F//+lde58+XnV2zJk2aJPO33normW+55ZbJvE+fPsn8+eefT+Y1be7cucm8os99L7vssmR+xRVXVHYk/j92tmqaNWuWzG+++eZkftxxxyXzBg0aJPP58+cn89133z2Zz549O5mfddZZyfzuu+9O5gMHDkzmRx55ZDJv3759Mk+p6L/NBRdckMwrem3Lli1L5uXl5ck8X+uys+6UAgAAACBzSikAAAAAMqeUAgAAACBzSikAAAAAMqeUAgAAACBzSikAAAAAMqeUAgAAACBzJblcLrdOTywpqelZKJDmzZsn8//85z/JfNNNN83r+i1btkzmCxcuzOv8xWwd13ONavvOtmrVKpk3btx4rdmHH35Y3ePUK927d0/mTz31VDLfYIMNqnztTz/9NJkfeeSRyfyf//xnMl++fHmlZ6pOdXlnKV7nnXdeMr/uuuvWmlW0s4sWLUrmBx10UDKfPHlyMq9pdnbNOnfunMzfeuutZD5r1qxkvvnmm1d6piz98Y9/TOYDBw5M5hMnTkzmXbp0qfRMfM3OrtkRRxyRzB944IFk/v777yfzit5H2rZtm8z333//ZH700Ucn80Lba6+9kvnNN9+czFOfO59++unJYx977LFkPmrUqGT+wgsvJPM777wzmedrXXbWnVIAAAAAZE4pBQAAAEDmlFIAAAAAZE4pBQAAAEDmlFIAAAAAZE4pBQAAAEDmlFIAAAAAZK600ANQeEceeWQy33TTTfM6//z585N5eXl5XuenOM2dO7fQI9RZu+++ezIfO3ZsMt9ggw2qcZpV9e7dO5m/9dZbNXZtqKuaNm2azPv27Vvlc5977rnJ/N57763yuam7mjdvnsw7duyYzN99993qHKfSli1bltfxX331VTVNAv9/rVu3Xmt24403Jo9t0KBBMq/oY37y5MnJ/LHHHkvmt956azKv7V544YVkfthhhyXzs88+e63ZI488UpWRVho4cGAyL4Z/c7lTCgAAAIDMKaUAAAAAyJxSCgAAAIDMKaUAAAAAyJxSCgAAAIDMKaUAAAAAyJxSCgAAAIDMlRZ6AArvrbfeSuZffPFFMm/RokUynzNnTjIvLy9P5sCqBg8enMyvvvrqZP6d73wnr+tXtNOnnXbaWrOJEyfmdW2oj/bZZ59k/sADDyTzjTbaKJnPnTt3rdkHH3yQPJa6adq0acn8qaeeSuZ9+vRJ5o8++mgy7969ezJftGhRMq/IAQcckMyPOeaYvM4/bty4vI6nfmrZsmUyf/jhh9eabbHFFnld+8svv0zmFf2dsHTp0ryuX+xmzpyZzIcNG7bWbMKECcljR40aVaWZiok7pQAAAADInFIKAAAAgMwppQAAAADInFIKAAAAgMwppQAAAADInFIKAAAAgMwppQAAAADIXGmhB6DwunTpksxbtGiR1/k/++yzZN6mTZtkPmPGjLyuD8Vmp512SubXXnttMt9ggw3yuv6nn36azA8++OBkPmHChLyuT3Fq2LDhWrNWrVolj91tt92S+aBBg6o007q69NJLk/kbb7yR1/kbNGiQzFu3bp3MK3qf3GijjZL5okWLkvlpp5221mz8+PHJY6mbKvqYGTZsWDLfYYcdknmnTp2S+eTJk5P5pEmTknlJSUky32+//ZJ5RTtbkRdffDGv46mfLr/88mTes2fPtWa5XC557KxZs5L5gAEDkvmSJUuSOVV3//33J/P9998/mZ9yyinJ/Ec/+lEy//GPf5zMs+BOKQAAAAAyp5QCAAAAIHNKKQAAAAAyp5QCAAAAIHNKKQAAAAAyp5QCAAAAIHNKKQAAAAAyV1roAah5G220UTLfaqutavT6u+66azI//fTTk/kFF1xQneNArXfaaacl8w022KBGr3/jjTcm8wkTJtTo9SlO55133lqzq666KsNJKu+9995L5m+88UZe5z/ppJOS+R133JHX+Sty6623JvNHHnmkRq9P3fPWW28l806dOiXzM888M5nvsssuyfyYY45J5vfff38yP//885P5FVdckcybN2+ezPfcc89k/sILLyRz6qdDDz00mZeXl1f53AceeGAyf+edd6p8bgorl8sl85kzZ2Y0SdW5UwoAAACAzCmlAAAAAMicUgoAAACAzCmlAAAAAMicUgoAAACAzCmlAAAAAMicUgoAAACAzJUWeoD6YIMNNkjmO+64YzLv2LFjMj/22GOTeZs2bZJ5586dk3lNGzVqVEGvD1m77LLLknn//v1r9PpTp05N5qNHj67R61Oc2rVrl8xPOOGEjCapfmeeeWYyP+KII5L5ueeem8xPOeWUSs9UGf/4xz+S+fDhw2v0+vBtX331VTL/5S9/mdf5K/rcN1+XXHJJMi8pKanR61M/dejQIZmn/q5//vnnk8dOmTKlSjNR83baaadkXtHHRUX+/Oc/53V8FtwpBQAAAEDmlFIAAAAAZE4pBQAAAEDmlFIAAAAAZE4pBQAAAEDmlFIAAAAAZE4pBQAAAEDmSgs9QH2w4447JvO//e1vGU1SGGPGjEnm//nPfzKaBLJxxBFHJPOf/exnybxhw4Z5XX/ZsmXJ/LjjjkvmM2fOzOv61E2PPPJIMu/UqVM2g9SA0tL0p0Obb755Mn/wwQerc5zV/OMf/0jmxx57bDKfP39+NU4DdV8ul8srh6r46quvkvnOO++81uy+++5LHrt06dIqzcTXNt5442Tetm3bZH7RRRetNTv00EOTx1b074KK/tuOGDEimdcG7pQCAAAAIHNKKQAAAAAyp5QCAAAAIHNKKQAAAAAyp5QCAAAAIHNKKQAAAAAyp5QCAAAAIHOlhR6gPnj99deT+e67757RJGv24IMPJvN27drldf5Zs2Yl8xUrVuR1fsha69atk/nIkSOTecOGDfO6/hdffJHMBw0alMzfeeedvK5P/dStW7dknsvlMpqk+CxatCiZ33rrrcl8+PDhyXz+/PmVHQmAWuZ3v/tdMj/77LPXmt10003JYxs0aJDM77333mT+6aefJvOa1rZt22TeuHHjZP75558n8wMOOCCZX3fddcl8s802S+Zz585dazZhwoQqHxtR8WzvvfdeMq8N3CkFAAAAQOaUUgAAAABkTikFAAAAQOaUUgAAAABkTikFAAAAQOaUUgAAAABkTikFAAAAQOZKCz1AffDFF18k83/+858ZTbJmixcvLuj1obZp1apVMn/kkUeSecuWLatxmtWVlZUl85/85CfJfMKECcl84cKFlZ4JWLuKduqnP/1pRpMAUFu98847yfzjjz9ea9akSZPksb/85S+T+ZlnnpnMn3322WTetWvXZP7www8n8y222CKZb7PNNsl8xx13TObz589P5hdccEEy79OnTzI/9dRTk/k//vGPtWYPPfRQ8tj6wJ1SAAAAAGROKQUAAABA5pRSAAAAAGROKQUAAABA5pRSAAAAAGROKQUAAABA5pRSAAAAAGSutNADAGTt8MMPT+ajR49O5o0bN67GaSrvwQcfTOaDBw9O5osXL67Ocagnli9fnswbNGiQ0SQAtVvnzp0LPQJF6I477kjm//nPf9aa/frXv04e+9577yXzLl26JPPTTjstmVf0OUL37t2TeXl5eTJ/5ZVXkvmvfvWrZP7ss88m8w8++CCZf/zxx8n8vPPOS+akuVMKAAAAgMwppQAAAADInFIKAAAAgMwppQAAAADInFIKAAAAgMwppQAAAADIXGmhB6DmtW/fPpmvv/762QwCGdltt92S+ahRo5J548aNq3Oc1SxYsCCZ/+xnP0vmI0eOTObLli2r9ExQkX322SeZ/+lPf1prtvHGG1fzNNVr7NixyXzmzJnJvEOHDsl8r732SuZnn312Mn///feTeUXzA9naYYcdCj0CRWjFihXJfPz48WvNpkyZkjx23Lhxyfy73/1uMj/ggAOS+dChQ5P54MGDk3lFn7s2bNgwmf/iF79I5tRu7pQCAAAAIHNKKQAAAAAyp5QCAAAAIHNKKQAAAAAyp5QCAAAAIHNKKQAAAAAyp5QCAAAAIHOlhR6Amrfbbrsl8zZt2tTo9d98880aPT98W58+fZJ5kyZNMppkzcaMGZPMb7vttowmgXX38ssvJ/Pjjjturdnw4cPzuvbs2bOT+cUXX5zX+WfMmJHMFyxYkMxbtGiRzG+66aa88oULFybzadOmJfOKvPbaa2vNTjnllLzODUDNO+qoo2r0/D/96U/zOv65556rpkmoi9wpBQAAAEDmlFIAAAAAZE4pBQAAAEDmlFIAAAAAZE4pBQAAAEDmlFIAAAAAZE4pBQAAAEDmSgs9ADWvW7duBb3+o48+WtDrU/c0atQomR9wwAEZTbJmo0ePTuZDhgzJaBLIzvjx49ea9ejRI7tBCuCLL75I5hdeeGEyP/HEE5N58+bNk/nWW2+dzIcOHZrMZ8+encyBylm6dGmhRwAoGu6UAgAAACBzSikAAAAAMqeUAgAAACBzSikAAAAAMqeUAgAAACBzSikAAAAAMqeUAgAAACBzpYUegJp34IEHFnoEqFadOnVK5rvuumuNXn/UqFHJfPDgwcm8vLy8OscBarnZs2cn8wYNGmQ0CZCFhx56qNAjABQNd0oBAAAAkDmlFAAAAACZU0oBAAAAkDmlFAAAAACZU0oBAAAAkDmlFAAAAACZU0oBAAAAkLmSXC6XW6cnlpTU9CzUkB/84AfJ/O67767R67du3TqZz5s3r0avX8zWcT3XqC7vbOPGjZP5+PHjk3mDBg2S+dVXX53Mn3rqqWT+1VdfJXPqLjsLxcXOsiaPPPJIMt9jjz2SeefOnZP5xx9/XNmR+P/YWSgu67Kz7pQCAAAAIHNKKQAAAAAyp5QCAAAAIHNKKQAAAAAyp5QCAAAAIHNKKQAAAAAyp5QCAAAAIHMluVwut05PLCmp6VmoIeutl+4ef/e73yXzk046KZkff/zxyfz+++9P5uv4IVgv5fNnY2che3YWioudheJiZ6G4rMvOulMKAAAAgMwppQAAAADInFIKAAAAgMwppQAAAADInFIKAAAAgMwppQAAAADInFIKAAAAgMyV5HK53Do9saSkpmcBvmUd13ON7Cxkz85CcbGzUFzsLBSXddlZd0oBAAAAkDmlFAAAAACZU0oBAAAAkDmlFAAAAACZU0oBAAAAkDmlFAAAAACZU0oBAAAAkLmSXC6XK/QQAAAAANQv7pQCAAAAIHNKKQAAAAAyp5QCAAAAIHNKKQAAAAAyp5QCAAAAIHNKKQAAAAAyp5QCAAAAIHNKKQAAAAAyp5QCAAAAIHNKKQAAAAAyp5QCAAAAIHNKKQAAAAAyp5QCAAAAIHNKKQAAAAAyp5QCAAAAIHNKqQIoKSlZp1/jx48v9KhrtHDhwhg6dGi0a9cuGjduHNtvv33ceuuthR4Lakyx72xExIIFC2LYsGHRoUOHaNy4cWy22WZx9NFHx5dfflno0aDaFfPOjh8/Pjnz1VdfXegRodoV885+w/ss9Umx72z79u3XOO/pp59e6NHqpdJCD1Af/fGPf1zl9/fcc088/fTTqz2+/fbbZznWOlmxYkX07ds3Xn311fjhD38Y22yzTTz55JNx5plnxmeffRYXXnhhoUeEalfMOxsR8fnnn8fee+8dH3zwQZx22mnRsWPH+OSTT+LFF1+MJUuWRFlZWaFHhGpVzDu7/fbbrzZnxNev6amnnoo+ffoUYCqoWcW8sxHeZ6l/in1nIyK6du0a55577iqPderUqUDT1G8luVwuV+gh6ruzzjorbrnllqjoP8WXX35Z8De1MWPGRL9+/WLkyJFx8sknr3z86KOPjr/+9a8xY8aM2HjjjQs4IdS8YtrZiIgzzzwz7rvvvpgwYUJ06NCh0ONA5optZ9dkm222iZKSkvjvf/9b6FGgxhXbznqfpb4rtp1t3759dO7cOR599NFCj0L48r1aa5999onOnTvHa6+9FnvttVeUlZWtvAuppKQkLrvsstWOad++fZx00kmrPDZ//vwYOnRobL755tG4cePo2LFjXHfddVFeXr7K8z766KOYPHlyLFu2LDnXiy++GBER/fv3X+Xx/v37x+LFi2Ps2LGVfKVQN9TWnZ0/f37cddddcdppp0WHDh1i6dKlsWTJkrxeK9QFtXVn1+Rf//pXvPvuuzFw4MBKHwt1RW3dWe+zsGa1dWf/19KlS2PRokWVfm1UL6VULTZ37tw48MADo2vXrnHTTTfFvvvuW6njv/zyy9h7773j3nvvjRNOOCF+/etfxx577BEXXHBB/OQnP1nluRdccEFsv/32MWvWrOQ5lyxZEg0aNIhGjRqt8vg3jfdrr71WqRmhLqmNO/v3v/89Fi9eHB07doyjjz46ysrKomnTprHHHnvEG2+8UdmXCHVKbdzZNRk1alREhFKKeq827qz3WVi72riz3/jb3/4WZWVl0bx582jfvn3cfPPNlZqN6uN7StVis2fPjttuuy2GDBlSpeNvvPHGmDp1arz++uuxzTbbRETEkCFDYtNNN43rr78+zj333Nh8880rdc5tt902VqxYEf/4xz+iZ8+eKx//5g6qqnyyDXVFbdzZKVOmRMTXb9Rbb7113HPPPfH555/H5ZdfHvvtt19MmjQp2rZtW6V5odjVxp39thUrVsQDDzwQu+yyS3Ts2DGvc0Gxq407630W1q427mxERJcuXaJnz56x7bbbxty5c+Puu++OoUOHxocffhjXXXddlWal6twpVYs1btw4Bg0aVOXjx4wZE3vuuWdsuOGG8emnn6781atXr1ixYkW88MILK5979913Ry6Xi/bt2yfPOWDAgGjZsmWcfPLJ8fTTT8f06dPjjjvuiN/+9rcREfHVV19VeV4odrVxZxcuXBgRX98m/eyzz8aAAQPijDPOiEceeSQ+++yzuOWWW6o8LxS72riz3/bss8/Gxx9/7C4piNq5s95nYe1q485GRIwbNy6GDRsW3//+9+Pkk0+O559/Pvr27Rs33nhjfPDBB1Wel6pxp1Qtttlmm632ZXKVMWXKlHjrrbeidevWa8znzJlT6XNusskmMW7cuPjBD36w8icAtWjRIkaMGBEnnnhiNG/evMrzQrGrjTvbtGnTiIg49NBDV9nP3XbbLTp06BAvv/xy1YaFOqA27uy3jRo1Kho0aBDHHnts3ueCYlcbd9b7LKxdbdzZNSkpKYkf//jH8eSTT8b48ePj+OOPr5bzsm6UUrXYN29y62rFihWr/L68vDx69+4dw4YNW+Pzq/ojL/faa69477334t///ncsWrQodtxxx/jwww/zOifUBbVxZzfddNOIiGjTps1q2cYbbxyfffZZpc8JdUVt3Nn/9dVXX8Wf//zn6NWr1xp3GOqb2riz3mdh7Wrjzq7NN18GOG/evGo7J+tGKVWENtxww5g/f/4qjy1dujQ++uijVR7beuutY+HChdGrV69qn6FBgwbRtWvXlb9/5plnIiJq5FpQ7Aq5s927d4+INX+/tw8//DC22267arsW1BW14X024usvL1iwYIEv3YMKeJ+F4lJb3mf/13vvvRcRsda7sqg5vqdUEdp6661X+frZiIg77rhjtWa5X79+8corr8STTz652jnmz58fy5cvX/n7fH5U9SeffBLXXXdddOnSRSkFa1DInd12221jxx13jLFjx8ann3668vGnnnoqZs6cGb17967KS4I6rba8z44ePTrKysriiCOOqOQrgPrF+ywUl0Lu7Lx581a7zrJly+Laa6+NRo0aVfonBJI/d0oVoVNPPTVOP/30OOqoo6J3797x5ptvxpNPPhkbbbTRKs87//zzY9y4cXHIIYfESSedFN27d49FixbFv//973jooYdi+vTpK4+54IIL4g9/+ENMmzatwm8Ot/fee0ePHj2iY8eOMXv27Ljjjjti4cKF8eijj8Z66+k54dsKvbO/+tWvonfv3tGzZ88YMmRIfP7553HjjTdGp06d4owzzqiplw1Fq9A7G/H1J82PP/54HHXUUb5fI1Sg0DvrfRYqp5A7O27cuLjqqqvi6KOPjg4dOsS8efNi9OjRMXHixLjmmmtik002qcmXzhoopYrQ4MGDY9q0aTFy5Mh44oknYs8994ynn3469t9//1WeV1ZWFs8//3xcc801MWbMmLjnnnuiRYsW0alTp7j88sujZcuWVbp+9+7dY8yYMTFr1qxo0aJF9O7dO6688srYaqutquPlQZ1T6J3dd99944knnoiLL744LrzwwigrK4vDDz88fvGLX/jHLqxBoXc24uufOLRs2bIYMGBAvi8H6rxC76z3WaicQu7s//3f/8V3v/vduPfee+OTTz6JRo0aRdeuXePBBx+MY445prpeIpVQksvlcoUeAgAAAID6xddaAQAAAJA5pRQAAAAAmVNKAQAAAJA5pRQAAAAAmVNKAQAAAJA5pRQAAAAAmVNK1VPt27ePk046qdBjAOvIzkJxsbNQXOwsFBc7W3copQrg7rvvjpKSkpW/mjRpEp06dYqzzjorPv7440KPt07efffdOProo2PDDTeMsrKy6NmzZzz33HOFHgtqRF3Y2YiIqVOnxoABA2LjjTeOpk2bxjbbbBM///nPCz0WVLti39nLLrtslfm//eull14q9IhQrYp9Z7/hfZb6oth3dvr06Wt9j73//vsLPV69U1roAeqzK664Ijp06BCLFy+Ov//973HrrbfGY489FhMnToyysrJCj7dWM2fOjB49ekSDBg3i/PPPj2bNmsVdd90Vffr0iWeffTb22muvQo8INaJYdzYi4o033oh99tknNttsszj33HOjVatW8f7778fMmTMLPRrUmGLd2SOPPDI6duy42uMXXnhhLFy4MHbeeecCTAU1r1h3NsL7LPVTMe9sRMRxxx0XBx100CqP9ejRo0DT1F9KqQI68MADY6eddoqIiFNPPTVatWoVN954Y4wdOzaOO+64NR6zaNGiaNasWZZjrubaa6+N+fPnx8SJE2PbbbeNiIjBgwfHdtttFz/+8Y/jtddeK+h8UFOKdWfLy8vjBz/4QWy33Xbx3HPPRdOmTQs6D2SlWHe2S5cu0aVLl1UemzlzZnzwwQdx6qmnRqNGjQo0GdSsYt1Z77PUV8W6s9/o1q1bHH/88YUeo97z5Xu1yH777RcREdOmTYuIiJNOOimaN28eU6dOjYMOOijWX3/9GDhwYER8/eZ30003xQ477BBNmjSJNm3axJAhQ+Kzzz5b5Zy5XC6uuuqqaNeuXZSVlcW+++4bkyZNWuP1p06dGlOnTq1wzhdffDG+973vrSykIiLKysrisMMOiwkTJsSUKVOq9Pqh2BTLzj711FMxceLEuPTSS6Np06bx5ZdfxooVK/J56VCUimVn1+S+++6LXC63cj6oD4plZ73PwteKZWf/16JFi2Lp0qWVfalUI6VULfLNArVq1WrlY8uXL4++ffvGxhtvHDfccEMcddRRERExZMiQOP/882OPPfaIm2++OQYNGhSjRo2Kvn37xrJly1Yef8kll8TFF18cO+64Y1x//fWx1VZbRZ8+fWLRokWrXX///feP/fffv8I5lyxZssb/A/TNLZrulKK+KJadfeaZZyIionHjxrHTTjtFs2bNoqysLPr37x/z5s3L688Aikmx7OyajBo1KjbffHNfIk+9Uiw7630WvlYsO/uNyy+/PJo3bx5NmjSJnXfeOZ566qmqvnTykSNzd911Vy4ics8880zuk08+yc2cOTN3//3351q1apVr2rRp7oMPPsjlcrnciSeemIuI3M9+9rNVjn/xxRdzEZEbNWrUKo8/8cQTqzw+Z86cXKNGjXIHH3xwrry8fOXzLrzwwlxE5E488cRVjt9yyy1zW265ZYXzH3roobkNNtgg98UXX6zyeI8ePXIRkbvhhhvW9Y8CikKx7+xhhx2Wi4hcq1atcgMHDsw99NBDuYsvvjhXWlqa23333Ve5FtQFxb6z3zZx4sRcROSGDRtW6WOhGBT7znqfpb4p9p2dMWNGrk+fPrlbb701N27cuNxNN92U22KLLXLrrbde7tFHH63Cnwj5UEoVwDdL/O1fW265Ze6JJ55Y+bxvlnjGjBmrHH/OOefkWrZsmZszZ07uk08+WeVX8+bNc6eeemoul8vlRo8enYuIVc6Zy3293Gta4nX12GOP5SIid+CBB+YmTJiQe+edd3I/+tGPcg0bNsxFRO7KK6+s0nmhtir2nd1vv/1yEZE74IADVnl8+PDhuYjIPf3001U6L9RWxb6z33bBBRfkIiL35ptvVsv5oLYp9p31Pkt9U+w7uyZz587NtWnTJrfttttW2zlZN77ReQHdcsst0alTpygtLY02bdrEtttuG+utt+pXVJaWlka7du1WeWzKlCnx+eefx8Ybb7zG886ZMyciImbMmBEREdtss80qeevWrWPDDTes8twHHnhgjBgxIn72s59Ft27dIiKiY8eOcfXVV8ewYcOiefPmVT431GbFurPffLntt7/h5IABA+KCCy6Il19+OXr16lXl80NtVaw7+79yuVyMHj06OnfuvNo3P4e6plh31vss9VWx7uyafOc734lBgwbFtddeGx988MFqM1NzlFIFtMsuu6z8aQVr07hx49UWu7y8PDbeeOMYNWrUGo9p3bp1tc24NmeddVYMGjQo3nrrrWjUqFF07do1Ro4cGRERnTp1qvHrQyEU685uuummERHRpk2bVR7/5hOBb39DSagrinVn/9dLL70UM2bMiOHDh2d2TSiUYt1Z77PUV8W6s2uz+eabR0TEvHnzlFIZUkoVoa233jqeeeaZ2GOPPZI/cnbLLbeMiK+b6K222mrl45988km1vDk2a9YsevTosfL3zzzzTDRt2jT22GOPvM8NdUmhd7Z79+7xu9/9LmbNmrXK4x9++GFEFO6NH2qrQu/s/xo1alSUlJTEgAEDquV8UBcVeme9z0LlFHpn1+a9996LCDubNT99rwj169cvVqxYEVdeeeVq2fLly2P+/PkREdGrV69o2LBhjBgxInK53Mrn3HTTTWs8bz4/qvrll1+Ohx9+OE455ZRo2bJllc4BdVWhd/b73/9+NG7cOO66664oLy9f+fidd94ZERG9e/euxKuBuq/QO/uNZcuWxZgxY6Jnz56xxRZbVOo1QH1S6J31PguVU+id/eSTT1Z7bNasWfH73/8+unTpEm3btl23F0K1cKdUEdp7771jyJAhMXz48HjjjTeiT58+0bBhw5gyZUqMGTMmbr755jj66KOjdevWcd5558Xw4cPjkEMOiYMOOihef/31ePzxx2OjjTZa7bzf/PjM6dOnJ68/Y8aM6NevXxx22GGxySabxKRJk+K2226LLl26xDXXXFMTLxmKWqF3dpNNNomf//zncckll8QBBxwQhx9+eLz55pvxu9/9Lo477rjYeeeda+JlQ9Eq9M5+48knn4y5c+fGwIEDq/PlQZ1T6J31PguVU+idHTZsWEydOjX233//2HTTTWP69Olx++23x6JFi+Lmm2+uiZdMglKqSN12223RvXv3uP322+PCCy+M0tLSaN++fRx//PGrfPncVVddFU2aNInbbrstnnvuudh1113jqaeeioMPPrjK127RokW0bds2fvOb38S8efNis802i3POOSd+/vOfx/rrr18dLw/qnELubETERRddFBtuuGGMGDEihg4duson0MDqCr2zEV9/6V7Dhg3jmGOOyftcUNcVeme9z0LlFHJn+/TpE7fddlvccsst8dlnn8UGG2wQe+21V1x00UUrf5AX2SnJ/e99cAAAAACQAd9TCgAAAIDMKaUAAAAAyJxSCgAAAIDMKaUAAAAAyJxSCgAAAIDMKaUAAAAAyJxSCgAAAIDMla7rE0tKSmpyDmANcrlclY+1s5A9OwvFxc5CcbGzUFzWZWfdKQUAAABA5pRSAAAAAGROKQUAAABA5pRSAAAAAGROKQUAAABA5pRSAAAAAGROKQUAAABA5pRSAAAAAGROKQUAAABA5pRSAAAAAGROKQUAAABA5pRSAAAAAGROKQUAAABA5pRSAAAAAGROKQUAAABA5koLPQBAfdOgQYNkfumllybziy++OJl/+eWXyXzPPfdM5hMmTEjmAAAA1cGdUgAAAABkTikFAAAAQOaUUgAAAABkTikFAAAAQOaUUgAAAABkTikFAAAAQOaUUgAAAABkrrTQAwDUNw8++GAyP/zww5N5eXl5Ml9vvfT/bygrK0vmAABAzevfv38yP/jgg/M6//jx45P5yJEj8zp/dXCnFAAAAACZU0oBAAAAkDmlFAAAAACZU0oBAAAAkDmlFAAAAACZU0oBAAAAkDmlFAAAAACZK8nlcrl1emJJSU3PAnzLOq7nGtnZmrPeeuk+/6KLLkrmF198cTKv6L/7FVdckcz/8Ic/JPOZM2cmc6rOzkJxsbMUwnHHHZfMTzvttGQ+bty4tWYTJkxIHvv8888n89rOzlII3bp1S+YnnnhiMt9jjz3WmnXt2jV5bEUft5MmTUrmy5YtS+bdu3dP5vlal511pxQAAAAAmVNKAQAAAJA5pRQAAAAAmVNKAQAAAJA5pRQAAAAAmVNKAQAAAJA5pRQAAAAAmSvJ5XK5dXpiSUlNzwJ8yzqu5xrZ2Zrz4x//OJnfcMMNeZ3/xBNPTOb33ntvXuen5thZKC52tn4qKytL5gcffHAy/+Uvf5nMK/q4at26dTJv1KhRMk95/fXXk3mvXr2S+eeff17la2fBzlIV/fr1S+Y//elPk/l2222XzJs0aZLMUx97c+bMSR47bNiwZP7ggw8m8+985zvJ/MMPP0zm+VqXnXWnFAAAAACZU0oBAAAAkDmlFAAAAACZU0oBAAAAkDmlFAAAAACZU0oBAAAAkDmlFAAAAACZK8nlcrl1emJJSU3PUm9dc801yfyss85K5uuvv34yr+g/8T//+c9kPnDgwGT+3nvvJXOqbh3Xc43sbNXtsMMOyfypp55K5ptsskkyf/PNN5P5gQcemMw//vjjZE7h2FkoLna2bjrkkEOS+aWXXprMv/e97yXziv7bV/RxNXHixGS+YMGCZP6Xv/xlrdkDDzyQPHbGjBnJvLazs3XTeuul75U58sgjk/l5552XzCva6dLS0mS+ePHiZD5p0qRknvr3fEU7Weyf96/LzrpTCgAAAIDMKaUAAAAAyJxSCgAAAIDMKaUAAAAAyJxSCgAAAIDMKaUAAAAAyFz6Zx+yTpo2bZrMR48encz333//ZP6rX/0qmd93333J/IgjjkjmZ555ZjIfNWpUMu/Zs2cyX7FiRTKH2qaindlkk03yOn9FP9a22H/0K9Q2Xbt2TebPPfdcMq/offySSy5J5nPnzk3mQOUceOCByfz3v/99Mv/Od76TzOfPn5/MH3vssWQ+bty4ZF7R3zn+zqCuadGiRTK//fbbk3m/fv2SeUlJSTLP5XLJvKJ/715zzTXJfPLkycmcNHdKAQAAAJA5pRQAAAAAmVNKAQAAAJA5pRQAAAAAmVNKAQAAAJA5pRQAAAAAmVNKAQAAAJC5klwul1unJ5aU1PQstVZZWVkyHzNmTDI/4IADkvlRRx2VzB955JFknq/1118/mb/99tvJ/MYbb0zmv/rVryo9E19bx/Vco/q8sxXZYIMNkvnkyZOTeevWrZP5Y489lsyPOeaYZL548eJkTu1lZ2unm266KZn/6Ec/yuv8CxcuTOZ/+9vfkvnEiROTeUV/J3366afJ/Iknnkjm+XzcFjs7WzvtvffeyXzs2LHJvHnz5sl8/vz5ybxPnz7JfMKECcmcmmNna6e99tormf/lL39J5hX9e7QiFb3PHXvsscl8wYIFeV2ftVuXnXWnFAAAAACZU0oBAAAAkDmlFAAAAACZU0oBAAAAkDmlFAAAAACZU0oBAAAAkDmlFAAAAACZKy30ALVBkyZNkvntt9+ezPv27ZvMjzrqqGQ+duzYZF7TFixYkMxffvnlZH7++ecn81tvvTWZL168OJlDdRsyZEgyb926dTKfMmVKMh84cGAy9zEP2dpll11q9PzNmzdP5ocddlheeUXmzJmTzLfddttkPn/+/LyuD9WtW7duyXz99dfP6/yLFi1K5hMmTMjr/FDXHHHEEcn897//fTKv6H3ytddeS+YnnXRSMp80aVIyp3ZzpxQAAAAAmVNKAQAAAJA5pRQAAAAAmVNKAQAAAJA5pRQAAAAAmVNKAQAAAJA5pRQAAAAAmSst9AC1wVFHHZXMBw4cmMx/9atfJfNHHnmksiMVlTZt2iTz0047LZn/+te/rs5xoEJ9+vTJ6/jnnnsumX/xxRd5nR/I1ltvvZXMK9rpnXbaKZk3adKk0jNVxvTp05O5v5MoNhdffHEyz+VyyXzu3LnJvKLPTaG+2WyzzZL5DTfckMxbtGiRzF9++eVk3rt372S+ePHiZE5xc6cUAAAAAJlTSgEAAACQOaUUAAAAAJlTSgEAAACQOaUUAAAAAJlTSgEAAACQOaUUAAAAAJkrLfQAtcHgwYOT+ZIlS5L59ddfX53j1DrNmzdP5iUlJcl8yy23rM5xoEJlZWXJvEWLFsm8vLw8mf/1r3+t9ExAzWnVqlUy/+53v5vM77jjjmQ+bNiwZN6+fftkvvXWWyfzSy+9NJnvueeeybxNmzbJfP3110/mn3/+eTKH6vajH/0ombds2TKZ53K5ZH722Wcn8yeffDKZQ30zYMCAZN6hQ4dkXtFOjhs3Lpk3a9Ysr7wiixYtSuaLFy/O6/zkx51SAAAAAGROKQUAAABA5pRSAAAAAGROKQUAAABA5pRSAAAAAGROKQUAAABA5pRSAAAAAGSutNAD1AatWrVK5mPHjk3ms2fPrs5xap099tgjmedyuWQ+ceLE6hwHKrTVVlsl827duiXzCRMmJPNHH3200jPVJhtvvHEy79u3b17nT/2d+PTTT+d1bliTPn36JPOWLVsm88WLF+d1/enTp+eVH3LIIcl8zz33TOY333xzMv/888+TOVS3ij63Pv3002v0+jNmzKjR80Ox2W677ZL5gAEDavT61157bV55RUpKSpL5pEmTkvn999+fzK+++upKz8S6c6cUAAAAAJlTSgEAAACQOaUUAAAAAJlTSgEAAACQOaUUAAAAAJlTSgEAAACQOaUUAAAAAJkrLfQAxWDWrFmFHqGoffjhh4UegXpm8ODBeR3/9NNPV9MkhdGvX79kfueddybzZs2a5XX9GTNmrDXbd999q3wsrE3r1q2T+YIFC5J5RTuRr0aNGiXzww8/PJnPnj07mY8bN66yI0GNKisrS+bbbLNNjV7/nHPOSebvvPNOMr/iiiuqcxwouEsvvTSZ77jjjsm8pKSkOseptFdffTWv43faaadkfuWVVybz448/Ppn/5Cc/SeaPP/54Mq/v3CkFAAAAQOaUUgAAAABkTikFAAAAQOaUUgAAAABkTikFAAAAQOaUUgAAAABkTikFAAAAQOZKCz0AxW/WrFnJ/M0338xoEuqL0tL0X10HHXRQRpMUxrHHHpvM//CHPyTzhg0bJvM33ngjmbdu3TqZb7nllmvNunbtmjx2xowZyRzW5LXXXkvmZ599djJ///33q3Oc1fzwhz9M5u3bt0/mf/zjH5P51KlTKzsSFFRJSUkyX2+99P83Ly8vT+b9+/ev9Ez/q6L3qiOPPDKv80N1a9euXTLv3LlzMs/lcsn8hRdeSOYPPfRQMl+wYEEy/8tf/pLX8RVZf/31k/kDDzyQzPfbb79k/vDDDyfzpk2bJvP6zp1SAAAAAGROKQUAAABA5pRSAAAAAGROKQUAAABA5pRSAAAAAGROKQUAAABA5pRSAAAAAGSutNAD1AZz585N5ieccEIyf+edd5L5HXfcUemZstS3b99k3rhx42Q+ceLEZD579uxKzwQp5eXlyfyNN95I5ltttVU1TlP9OnfunMzvvPPOZN6wYcNkPn78+GQ+aNCgZH7GGWck82HDhq01KysrSx4LVfHSSy/llde03XffPa/jx4wZU02TQO2Qy+WSeUXv8++//34ynzJlSjLfb7/9kvlhhx2WzC+55JJkfsUVVyRzqG5ffvllMp82bVoyr+hzx3POOSeZv/XWW8m80ObNm5fMr7zyymTepUuXZL7RRhsl83333Xet2XPPPZc8tj5wpxQAAAAAmVNKAQAAAJA5pRQAAAAAmVNKAQAAAJA5pRQAAAAAmVNKAQAAAJA5pRQAAAAAmSst9AC1wemnn57Mx4wZk8xvu+22ZH7ttdcm83/+85/JvCIlJSXJ/Lvf/W4yb9euXY1eH6pbeXl5Mv/LX/6SzI888shkfuaZZybzq6++OpkvWrQombdo0SKZX3TRRcm8rKwsmY8ePTqZDxo0KJkvX748mTdv3jyZ19SxUFsdcsghyfzQQw9N5vPnz0/m+X6eAHVNRe+Dl1xySTIfMWJEMv/zn/+czIcMGZLMH3vssWT+6quvJnPqp0aNGiXzfffdd63Zueeemzz2ww8/TOaHHXZYMv/vf/+bzItd3759k/lGG22U1/k/+uijvI6v69wpBQAAAEDmlFIAAAAAZE4pBQAAAEDmlFIAAAAAZE4pBQAAAEDmlFIAAAAAZE4pBQAAAEDmSgs9QG0wefLkZL777rsn82233TaZ77nnnsl81113TeZz585N5k2aNEnmY8aMSeb//Oc/k/lLL72UzHO5XDKHrD3yyCPJ/LzzzkvmO+ywQzK/6667knm/fv2S+RNPPJHMK/o74fnnn0/mJ598cjJfvnx5Mt90002T+SmnnJLM58+fv9bs3XffTR4Lxahbt27JvHHjxsn8uuuuS+apnYLaaMWKFcl8wYIFybxFixbJvFWrVsm8os9N33jjjWRekU022SSZn3vuucn8uOOOy+v61E333ntvMj/qqKNq7NozZsxI5pdeemmNXTsLO+20UzIfNGhQXuefNm1aMv/iiy/yOn9d504pAAAAADKnlAIAAAAgc0opAAAAADKnlAIAAAAgc0opAAAAADKnlAIAAAAgc0opAAAAADJXWugBisGCBQuS+auvvppXXtvlcrlCjwCV8sUXXyTzTz75JK/zH3zwwcn8sssuS+Y77LBDXtf/xS9+kcyXLVuWzNu2bZvM//rXvybzxo0bJ/OXX355rdlzzz2XPBaKUefOnfM6/o9//GMyX7p0aV7nh6x9+OGHyXzkyJHJ/Mc//nF1jrOaww47rEbPD1WxZMmSZF5SUlJj1z755JOT+aWXXlpj187CE088kcy/853v5HX+1157LZlX9HdifedOKQAAAAAyp5QCAAAAIHNKKQAAAAAyp5QCAAAAIHNKKQAAAAAyp5QCAAAAIHNKKQAAAAAyV1roAQCy1rdv32R+7733JvNjjjkmmV988cWVnqkyBg4cmMwPO+ywZH7qqacm8wYNGiTzzz77LJnfcMMNyRyKTevWrZP5vvvum8xffvnlZD5jxoxKzwTF7MUXX0zm5557bjIvLy9P5v3790/m++yzTzIvKSlJ5q+//noyP/3005M5rMnIkSOTeb9+/daalZam/1n/hz/8IZnff//9ybzQNtpoo2R+0EEHJfOmTZsm81wul8yffvrpZH788ccnc9LcKQUAAABA5pRSAAAAAGROKQUAAABA5pRSAAAAAGROKQUAAABA5pRSAAAAAGROKQUAAABA5koLPQBA1pYvX57ML7roomS+YMGCZH7yySdXeqbKGDBgQI2ef9asWcm8T58+yXzy5MnVOQ4U3PHHH5/MN9poo2R+ySWXJPNly5ZVeiYoZmPHjk3m5eXlyTyXyyXzs88+u9IzVeb8v/71r5P5559/ntf1qZ/Gjx+fzF966aW1ZnvvvXfy2O222y6ZL168OJl37NgxmVf0PnjAAQck806dOiXzffbZJ5k3a9YsmTdp0iSZz507N5lfeeWVydz7eH7cKQUAAABA5pRSAAAAAGROKQUAAABA5pRSAAAAAGROKQUAAABA5pRSAAAAAGSutNADUPxKSkoKPQJUq3fffTeZV/Sjph9++OFkfvHFFyfzXXfdNZlX5Msvv0zmV199dTK/6667kvnHH39c6ZmgmG2xxRbJfOLEicn8gQceqM5xoM779a9/ncwreh/O1/Tp05P5PffcU6PXhzX5xz/+sdasZ8+eyWMr+tzyueeeS+YV/Xsvl8sl85o2b968ZF7R57633357Mp81a1alZ2LduVMKAAAAgMwppQAAAADInFIKAAAAgMwppQAAAADInFIKAAAAgMwppQAAAADInFIKAAAAgMyVFnoAar/nn38+mX/ve9/LaBKoHRYvXpzMH3/88bxyIFtNmzZN5occckgyv++++5L5vHnzKj0T1Gdvv/12Mp87d24yb9WqVTJfsWJFMh8+fHgyh0K48MIL15o98cQTyWMPOuigZD5+/Phk3rZt22Re0U4uXbo0meerotdP7eZOKQAAAAAyp5QCAAAAIHNKKQAAAAAyp5QCAAAAIHNKKQAAAAAyp5QCAAAAIHNKKQAAAAAyV1roAaj9Jk2alMwPOeSQZN6xY8dk/u6771Z6JgCoLqeffnoyr+h97KOPPqrOcaDe+93vfpfMn3/++WT++OOPJ/NHH300mY8cOTKZQ23zwgsv5JVDIblTCgAAAIDMKaUAAAAAyJxSCgAAAIDMKaUAAAAAyJxSCgAAAIDMKaUAAAAAyJxSCgAAAIDMlRZ6AGq/F154IZn/9Kc/TeY77LBDMn/33XcrPRMAVJctttgir+NfeumlapoEWBf//e9/k/nWW2+d0SQA5MudUgAAAABkTikFAAAAQOaUUgAAAABkTikFAAAAQOaUUgAAAABkTikFAAAAQOaUUgAAAABkrrTQA1D7TZo0Ka/j99prr2Q+duzYvM4PACllZWXJ/JBDDknmEyZMSOYzZ86s9EwAALhTCgAAAIACUEoBAAAAkDmlFAAAAACZU0oBAAAAkDmlFAAAAACZU0oBAAAAkDmlFAAAAACZKy30ANR+M2fOTOYNGjTIaBIAqLyNNtoomW+yySbJ/JRTTknmn332WaVnAgDAnVIAAAAAFIBSCgAAAIDMKaUAAAAAyJxSCgAAAIDMKaUAAAAAyJxSCgAAAIDMKaUAAAAAyFxJLpfLrdMTS0pqehbgW9ZxPdfIzkL27CwUFzsLxcXOQnFZl511pxQAAAAAmVNKAQAAAJA5pRQAAAAAmVNKAQAAAJA5pRQAAAAAmVNKAQAAAJA5pRQAAAAAmSvJ5XK5Qg8BAAAAQP3iTikAAAAAMqeUAgAAACBzSikAAAAAMqeUAgAAACBzSikAAAAAMqeUAgAAACBzSikAAAAAMqeUAgAAACBzSikAAAAAMvf/A64irdnuoUORAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1200x600 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test DigitClassifier\n",
    "classifier.eval()\n",
    "\n",
    "# Get a batch for testing\n",
    "dataiter = iter(train_dataloader)\n",
    "images, labels = next(dataiter)\n",
    "images, labels = images.to(device), labels.to(device)\n",
    "batch_size = images.shape[0]\n",
    "\n",
    "with torch.no_grad():\n",
    "    flat_images = images.view(batch_size, -1)  # Flatten to (batch, 784)\n",
    "    outputs = classifier(flat_images)  # (batch, 10)\n",
    "    _, predicted = torch.max(outputs, 1)  # Get predicted class indices\n",
    "\n",
    "# Calculate accuracy\n",
    "correct = (predicted == labels).sum().item()\n",
    "accuracy = correct / batch_size * 100\n",
    "print(f\"Test Accuracy on batch: {accuracy:.2f}%\")\n",
    "print(f\"Correct predictions: {correct} out of {batch_size}\")\n",
    "\n",
    "# Visualize some predictions\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 6))\n",
    "axes = axes.ravel()\n",
    "for idx in range(10):\n",
    "    ax = axes[idx]\n",
    "    img = images[idx].cpu().numpy().squeeze()  # (1, 28, 28) -> (28, 28)\n",
    "    ax.imshow(img, cmap='gray')\n",
    "    ax.set_title(f\"True: {labels[idx].item()}\\nPred: {predicted[idx].item()}\")\n",
    "    ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c1af2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def sample(model, n_samples=1, img_size=28, channels=1, label=None):\n",
    "    model.eval()\n",
    "    if label is None:\n",
    "        labels = torch.randint(0, 10, (n_samples,)).to(device)\n",
    "    else:\n",
    "        labels = torch.full((n_samples,), label, device=device)\n",
    "    labels_one_hot = F.one_hot(labels, num_classes=10).float()\n",
    "    x = torch.randn((n_samples, channels, img_size, img_size)).to(device)\n",
    "    for t in reversed(range(1, T)):\n",
    "        t_batch = torch.full((n_samples,), t, device=device, dtype=torch.long)\n",
    "        beta_t = betas[t].to(device)\n",
    "        sqrt_one_minus_alphas_cumprod_t = sqrt_one_minus_alphas_cumprod[t].to(device)\n",
    "        sqrt_recip_alpha_t = (1.0 / torch.sqrt(alphas[t])).to(device)\n",
    "        epsilon_theta = model(x, t_batch.float(), labels_one_hot)\n",
    "        model_mean = sqrt_recip_alpha_t * (x - beta_t * epsilon_theta / sqrt_one_minus_alphas_cumprod_t)\n",
    "        if t > 1:\n",
    "            noise = torch.randn_like(x).to(device)\n",
    "            sigma_t = torch.sqrt(beta_t)\n",
    "            x = model_mean + sigma_t * noise\n",
    "        else:\n",
    "            x = model_mean\n",
    "    x = torch.clamp(x, -1, 1)\n",
    "    return x * 0.5 + 0.5  # Unnormalize to [0, 1] for plotting and classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38b89577",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69811/3776469776.py:6: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    }
   ],
   "source": [
    "# Train Guided Diffusion Model\n",
    "checkpoint_path_diffusion = \"checkpoint_diffusion.pth\"\n",
    "model = UNet().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "mse = nn.MSELoss()\n",
    "scaler = GradScaler()\n",
    "epochs = 200\n",
    "\n",
    "# Load pre-trained classifier\n",
    "checkpoint_classifier = torch.load(\"checkpoint_classifier.pth\")\n",
    "classifier = DigitClassifier().to(device)\n",
    "classifier.load_state_dict(checkpoint_classifier['classifier_state_dict'])\n",
    "classifier.eval()  # Freeze classifier, no training\n",
    "\n",
    "if os.path.exists(checkpoint_path_diffusion):\n",
    "    checkpoint = torch.load(checkpoint_path_diffusion)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    start_epoch = checkpoint['epoch'] + 1\n",
    "    losses_per_epoch = checkpoint['losses_per_epoch']\n",
    "    psnrs_per_epoch = checkpoint['psnrs_per_epoch']\n",
    "    accuracies_per_epoch = checkpoint['accuracies_per_epoch']\n",
    "    print(f\"Resumed diffusion training from epoch {start_epoch}\")\n",
    "else:\n",
    "    start_epoch = 0\n",
    "    losses_per_epoch = []\n",
    "    psnrs_per_epoch = []\n",
    "    accuracies_per_epoch = []\n",
    "\n",
    "def psnr(pred, target, max_val=1.0):\n",
    "    mse = torch.mean((pred - target) ** 2)\n",
    "    return 20 * torch.log10(max_val / torch.sqrt(mse)) if mse > 0 else float('inf')\n",
    "\n",
    "@torch.no_grad()\n",
    "def sample(model, n_samples=64, img_size=28, channels=1, label=None):\n",
    "    model.eval()\n",
    "    if label is None:\n",
    "        labels = torch.randint(0, 10, (n_samples,)).to(device)\n",
    "    else:\n",
    "        labels = torch.full((n_samples,), label, device=device)\n",
    "    labels_one_hot = F.one_hot(labels, num_classes=10).float()\n",
    "    x = torch.randn((n_samples, channels, img_size, img_size)).to(device)\n",
    "    for t in reversed(range(1, T)):\n",
    "        t_batch = torch.full((n_samples,), t, device=device, dtype=torch.long)\n",
    "        beta_t = betas[t].to(device)\n",
    "        sqrt_one_minus_alphas_cumprod_t = sqrt_one_minus_alphas_cumprod[t].to(device)\n",
    "        sqrt_recip_alpha_t = (1.0 / torch.sqrt(alphas[t])).to(device)\n",
    "        epsilon_theta = model(x, t_batch.float(), labels_one_hot)\n",
    "        model_mean = sqrt_recip_alpha_t * (x - beta_t * epsilon_theta / sqrt_one_minus_alphas_cumprod_t)\n",
    "        if t > 1:\n",
    "            noise = torch.randn_like(x).to(device)\n",
    "            sigma_t = torch.sqrt(beta_t)\n",
    "            x = model_mean + sigma_t * noise\n",
    "        else:\n",
    "            x = model_mean\n",
    "    x = torch.clamp(x, -1, 1)\n",
    "    return x * 0.5 + 0.5  # Unnormalize to [0, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "664f3280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting diffusion training...\n",
      "\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/938 [00:00<?, ?it/s]/tmp/ipykernel_69811/1128395738.py:14: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Loss: 0.0457 | PSNR: 4.55:  45%|████▌     | 426/938 [00:52<01:02,  8.17it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     20\u001b[0m scaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 21\u001b[0m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m scaler\u001b[38;5;241m.\u001b[39mupdate()\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# PSNR calculation\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/number-gen/.venv/lib/python3.10/site-packages/torch/amp/grad_scaler.py:461\u001b[0m, in \u001b[0;36mGradScaler.step\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munscale_(optimizer)\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m    458\u001b[0m     \u001b[38;5;28mlen\u001b[39m(optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    459\u001b[0m ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo inf checks were recorded for this optimizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 461\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_opt_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    463\u001b[0m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstage\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m OptState\u001b[38;5;241m.\u001b[39mSTEPPED\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[0;32m~/Desktop/number-gen/.venv/lib/python3.10/site-packages/torch/amp/grad_scaler.py:355\u001b[0m, in \u001b[0;36mGradScaler._maybe_opt_step\u001b[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_maybe_opt_step\u001b[39m(\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    349\u001b[0m     optimizer: torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mOptimizer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    353\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[1;32m    354\u001b[0m     retval: Optional[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 355\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf_per_device\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    356\u001b[0m         retval \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[0;32m~/Desktop/number-gen/.venv/lib/python3.10/site-packages/torch/amp/grad_scaler.py:355\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_maybe_opt_step\u001b[39m(\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    349\u001b[0m     optimizer: torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mOptimizer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    353\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[1;32m    354\u001b[0m     retval: Optional[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 355\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    356\u001b[0m         retval \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Starting diffusion training...\")\n",
    "for epoch in range(start_epoch, epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
    "    pbar = tqdm.tqdm(train_dataloader)\n",
    "    total_loss, step_count, total_psnr = 0, 0, 0\n",
    "\n",
    "    model.train()\n",
    "    for step, (x, labels) in enumerate(pbar):\n",
    "        x = x.to(device)  # (batch, 1, 28, 28)\n",
    "        labels_one_hot = F.one_hot(labels, num_classes=10).float().to(device)\n",
    "        batch_size = x.shape[0]\n",
    "        t = torch.randint(0, T, (batch_size,), device=device).long()\n",
    "\n",
    "        with autocast():\n",
    "            x_t, noise = forward_diffusion_sample(x, t)\n",
    "            noise_pred = model(x_t, t.float(), labels_one_hot)\n",
    "            loss = mse(noise_pred, noise)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # PSNR calculation\n",
    "        alpha_bar = sqrt_alphas_cumprod[t][:, None, None, None]\n",
    "        one_minus_alpha_bar = sqrt_one_minus_alphas_cumprod[t][:, None, None, None]\n",
    "        x0_pred = (x_t - one_minus_alpha_bar * noise_pred) / alpha_bar\n",
    "        x0_pred = torch.clamp(x0_pred, -1, 1)\n",
    "        batch_psnr = psnr(x0_pred, x)\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_psnr += batch_psnr.item()\n",
    "        step_count += 1\n",
    "        pbar.set_description(f\"Loss: {loss.item():.4f} | PSNR: {batch_psnr.item():.2f}\")\n",
    "\n",
    "    avg_loss = total_loss / step_count\n",
    "    avg_psnr = total_psnr / step_count\n",
    "    losses_per_epoch.append(avg_loss)\n",
    "    psnrs_per_epoch.append(avg_psnr)\n",
    "\n",
    "    # Evaluate accuracy every 10 epochs\n",
    "    if epoch % 10 == 0 or epoch == epochs - 1:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            samples = sample(model, n_samples=64, label=None)\n",
    "            flat_samples = samples.view(64, -1)\n",
    "            pred_labels = classifier(flat_samples)\n",
    "            _, predicted = torch.max(pred_labels, 1)\n",
    "            true_labels = torch.randint(0, 10, (64,)).to(device)  # Approx, improve with validation later\n",
    "            correct_preds = (predicted == true_labels).sum().item()\n",
    "            total_preds = 64\n",
    "            accuracy = correct_preds / total_preds * 100 if total_preds > 0 else 0\n",
    "            accuracies_per_epoch.append(accuracy)\n",
    "        model.train()\n",
    "\n",
    "    print(f\"Average Loss: {avg_loss:.6f} | Average PSNR: {avg_psnr:.2f} | Accuracy (every 10 epochs): {accuracy if epoch % 10 == 0 or epoch == epochs - 1 else 'N/A'}%\")\n",
    "\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'losses_per_epoch': losses_per_epoch,\n",
    "        'psnrs_per_epoch': psnrs_per_epoch,\n",
    "        'accuracies_per_epoch': accuracies_per_epoch,\n",
    "    }, checkpoint_path_diffusion)\n",
    "    print(f\"Diffusion checkpoint saved at epoch {epoch+1}\")\n",
    "\n",
    "    # Plotting\n",
    "    clear_output(wait=True)\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(range(1, epoch + 2), losses_per_epoch, label='MSE Loss')\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Loss vs Epoch\")\n",
    "    plt.grid(True)\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(range(1, epoch + 2), psnrs_per_epoch, label='PSNR (dB)', color='orange')\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"PSNR\")\n",
    "    plt.title(\"PSNR vs Epoch\")\n",
    "    plt.grid(True)\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.plot(range(10, epoch + 2, 10) if epoch >= 9 else [epoch + 1], accuracies_per_epoch, label='Accuracy (%)', color='green')\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(\"Accuracy vs Epoch\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
